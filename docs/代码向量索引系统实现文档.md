# ä»£ç å‘é‡ç´¢å¼•ç³»ç»Ÿå®Œæ•´å®ç°æ–‡æ¡£

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
2. [æŠ€æœ¯æ¶æ„](#æŠ€æœ¯æ¶æ„)
3. [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
4. [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)
5. [ä»£ç å®ç°](#ä»£ç å®ç°)
6. [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
7. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

## ğŸ¯ ç³»ç»Ÿæ¦‚è¿°

### åŠŸèƒ½ç‰¹æ€§

- **æ™ºèƒ½ä»£ç è§£æ**: ä½¿ç”¨Tree-sitterè¿›è¡Œè¯­æ³•æ„ŸçŸ¥çš„ä»£ç åˆ†å—
- **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒOpenAIã€Ollamaã€Geminiã€Mistralç­‰embeddingæ¨¡å‹
- **é«˜æ€§èƒ½æœç´¢**: åŸºäºQdrantå‘é‡æ•°æ®åº“çš„æ¯«ç§’çº§è¯­ä¹‰æœç´¢
- **å®æ—¶ç´¢å¼•**: æ–‡ä»¶å˜åŒ–ç›‘æ§å’Œå¢é‡ç´¢å¼•æ›´æ–°
- **æ‰¹é‡å¤„ç†**: ä¼˜åŒ–çš„æ‰¹å¤„ç†æœºåˆ¶æé«˜ç´¢å¼•æ•ˆç‡
- **è·¯å¾„è¿‡æ»¤**: æ”¯æŒç›®å½•çº§åˆ«çš„æœç´¢è¿‡æ»¤

### æŠ€æœ¯æ ˆ

- **å‘é‡æ•°æ®åº“**: Qdrant (HNSWç®—æ³•)
- **Embeddingæ¨¡å‹**: OpenAI/Ollama/Gemini/Mistral
- **ä»£ç è§£æ**: Tree-sitter
- **è¯­è¨€æ”¯æŒ**: TypeScript/JavaScript/Python/Go/Rust/Javaç­‰
- **é€šä¿¡åè®®**: HTTP/HTTPS REST API

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ä»£ç æ–‡ä»¶       â”‚    â”‚   Roo Code       â”‚    â”‚   Qdrant DB     â”‚
â”‚                â”‚    â”‚   æ™ºèƒ½å®¢æˆ·ç«¯      â”‚    â”‚   å‘é‡æ•°æ®åº“     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ .js/.ts      â”‚â”€â”€â”€â–¶â”‚ â€¢ ä»£ç è§£æ        â”‚â”€â”€â”€â–¶â”‚ â€¢ å‘é‡å­˜å‚¨       â”‚
â”‚ â€¢ .py/.go      â”‚    â”‚ â€¢ è¯­ä¹‰åˆ†å—        â”‚    â”‚ â€¢ ç›¸ä¼¼åº¦æœç´¢     â”‚
â”‚ â€¢ .java/.rs    â”‚    â”‚ â€¢ å‘é‡åŒ–å¤„ç†      â”‚    â”‚ â€¢ HNSWç´¢å¼•      â”‚
â”‚ â€¢ å…¶ä»–è¯­è¨€      â”‚    â”‚ â€¢ æ‰¹é‡ä¸Šä¼         â”‚    â”‚ â€¢ é›†åˆç®¡ç†       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµå‘

```
ä»£ç æ‰«æ â†’ è¯­æ³•è§£æ â†’ æ™ºèƒ½åˆ†å— â†’ å‘é‡åŒ– â†’ æ‰¹é‡ä¸Šä¼  â†’ Qdrantå­˜å‚¨
   â†“         â†“        â†“        â†“        â†“         â†“
æ–‡ä»¶ç›‘æ§ â† å¢é‡æ›´æ–° â† å˜åŒ–æ£€æµ‹ â† å‘é‡æœç´¢ â† HTTP API â† ç”¨æˆ·æŸ¥è¯¢
```

## ğŸ§© æ ¸å¿ƒç»„ä»¶

### 1. å‘é‡å­˜å‚¨æ¥å£ (IVectorStore)

```typescript
interface IVectorStore {
    // åˆå§‹åŒ–å‘é‡é›†åˆ
    initializeCollection(): Promise<boolean>
    
    // æ‰¹é‡æ’å…¥å‘é‡æ•°æ®
    upsertPoints(points: Array<{
        id: string
        vector: number[]
        payload: Record<string, any>
    }>): Promise<void>
    
    // å‘é‡ç›¸ä¼¼åº¦æœç´¢
    search(
        queryVector: number[],
        directoryPrefix?: string,
        minScore?: number,
        maxResults?: number
    ): Promise<VectorStoreSearchResult[]>
    
    // åˆ é™¤æŒ‡å®šæ–‡ä»¶çš„å‘é‡æ•°æ®
    deletePointsByFilePath(filePath: string): Promise<void>
}
```

### 2. Embeddingæ¥å£ (IEmbedder)

```typescript
interface IEmbedder {
    // æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡
    createEmbeddings(texts: string[]): Promise<EmbeddingResponse>
    
    // è·å–å‘é‡ç»´åº¦
    getDimension(): number
    
    // è·å–æ¨¡å‹ä¿¡æ¯
    getModelInfo(): { provider: string; model: string }
}
```

### 3. ä»£ç ç´¢å¼•ç®¡ç†å™¨

```typescript
interface ICodeIndexManager {
    // å…¨é‡æ‰«æå’Œç´¢å¼•
    scanAndIndex(
        workspacePath: string,
        onProgress?: (progress: ScanProgress) => void
    ): Promise<void>
    
    // è¯­ä¹‰æœç´¢
    searchIndex(
        query: string,
        directoryPrefix?: string
    ): Promise<VectorStoreSearchResult[]>
    
    // å¯åŠ¨æ–‡ä»¶ç›‘æ§
    startWatching(): void
    
    // åœæ­¢æ–‡ä»¶ç›‘æ§
    stopWatching(): void
}
```

## ğŸš€ éƒ¨ç½²æŒ‡å—

### 1. Qdrantéƒ¨ç½²

#### Dockeræ–¹å¼ï¼ˆæ¨èï¼‰

```bash
# åŸºç¡€éƒ¨ç½²
docker run -p 6333:6333 qdrant/qdrant

# æŒä¹…åŒ–å­˜å‚¨
docker run -p 6333:6333 -v $(pwd)/qdrant_storage:/qdrant/storage qdrant/qdrant
```

#### Docker Composeæ–¹å¼

```yaml
version: '3.8'
services:
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - ./qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
    restart: unless-stopped
```

#### äº‘ç«¯éƒ¨ç½²

```typescript
// Qdrant Cloudé…ç½®ç¤ºä¾‹
const config = {
    url: "https://your-cluster.qdrant.io",
    apiKey: "your-api-key"
}
```

### 2. ç¯å¢ƒé…ç½®

```bash
# å®‰è£…ä¾èµ–
npm install @qdrant/js-client-rest
npm install openai
npm install chokidar  # æ–‡ä»¶ç›‘æ§
npm install tree-sitter  # ä»£ç è§£æ
```

## ğŸ’» ä»£ç å®ç°

### 1. Qdrantå‘é‡å­˜å‚¨å®ç°

```typescript
import { QdrantClient } from "@qdrant/js-client-rest"

export class QdrantVectorStore implements IVectorStore {
    private client: QdrantClient
    private collectionName: string
    private vectorSize: number
    
    constructor(workspacePath: string, url: string, vectorSize: number, apiKey?: string) {
        // è§£æURLé…ç½®
        const urlObj = new URL(url)
        
        this.client = new QdrantClient({
            host: urlObj.hostname,
            https: urlObj.protocol === "https:",
            port: urlObj.port ? Number(urlObj.port) : (urlObj.protocol === "https:" ? 443 : 80),
            apiKey,
            headers: {
                "User-Agent": "Code-Vector-Index",
            },
        })
        
        // ç”Ÿæˆé›†åˆåç§°
        const hash = createHash("sha256").update(workspacePath).digest("hex")
        this.collectionName = `workspace-${hash.substring(0, 16)}`
        this.vectorSize = vectorSize
    }
    
    async initializeCollection(): Promise<boolean> {
        try {
            // æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            const collections = await this.client.getCollections()
            const exists = collections.collections.some(c => c.name === this.collectionName)
            
            if (exists) {
                return false // é›†åˆå·²å­˜åœ¨
            }
            
            // åˆ›å»ºæ–°é›†åˆ
            await this.client.createCollection(this.collectionName, {
                vectors: {
                    size: this.vectorSize,
                    distance: "Cosine",  // ä½™å¼¦ç›¸ä¼¼åº¦
                    on_disk: true,       // ç£ç›˜å­˜å‚¨
                },
                hnsw_config: {
                    m: 64,               // HNSWå‚æ•°
                    ef_construct: 512,
                    on_disk: true,
                },
            })
            
            // åˆ›å»ºpayloadç´¢å¼•
            await this._createPayloadIndexes()
            return true
        } catch (error) {
            console.error("Failed to initialize collection:", error)
            throw error
        }
    }
    
    private async _createPayloadIndexes(): Promise<void> {
        // ä¸ºæ–‡ä»¶è·¯å¾„åˆ›å»ºç´¢å¼•
        await this.client.createPayloadIndex(this.collectionName, {
            field_name: "filePath",
            field_schema: "keyword"
        })
        
        // ä¸ºè·¯å¾„æ®µåˆ›å»ºç´¢å¼•ï¼ˆæ”¯æŒç›®å½•è¿‡æ»¤ï¼‰
        for (let i = 0; i < 10; i++) {
            await this.client.createPayloadIndex(this.collectionName, {
                field_name: `pathSegments.${i}`,
                field_schema: "keyword"
            })
        }
    }
}
```

### 2. OpenAI Embeddingå®ç°

```typescript
import OpenAI from "openai"

export class OpenAiEmbedder implements IEmbedder {
    private client: OpenAI
    private model: string
    private dimension: number
    
    constructor(apiKey: string, model: string = "text-embedding-3-small") {
        this.client = new OpenAI({ apiKey })
        this.model = model
        this.dimension = this._getModelDimension(model)
    }
    
    async createEmbeddings(texts: string[]): Promise<EmbeddingResponse> {
        const batchSize = 100 // OpenAIæ‰¹æ¬¡é™åˆ¶
        const allEmbeddings: number[][] = []
        let totalTokens = 0
        
        // åˆ†æ‰¹å¤„ç†
        for (let i = 0; i < texts.length; i += batchSize) {
            const batch = texts.slice(i, i + batchSize)
            
            const response = await this.client.embeddings.create({
                input: batch,
                model: this.model,
            })
            
            allEmbeddings.push(...response.data.map(item => item.embedding))
            totalTokens += response.usage?.total_tokens || 0
        }
        
        return {
            embeddings: allEmbeddings,
            usage: {
                promptTokens: 0,
                totalTokens,
            }
        }
    }
    
    getDimension(): number {
        return this.dimension
    }
    
    private _getModelDimension(model: string): number {
        const dimensions: Record<string, number> = {
            "text-embedding-3-small": 1536,
            "text-embedding-3-large": 3072,
            "text-embedding-ada-002": 1536,
        }
        return dimensions[model] || 1536
    }
}
```

### 3. ä»£ç æ‰«æå’Œç´¢å¼•å¤„ç†å™¨

```typescript
import * as chokidar from "chokidar"
import { v5 as uuidv5 } from "uuid"

export class CodeIndexScanner {
    private embedder: IEmbedder
    private vectorStore: IVectorStore
    private workspacePath: string
    private batchSize: number = 60

    constructor(
        workspacePath: string,
        embedder: IEmbedder,
        vectorStore: IVectorStore
    ) {
        this.workspacePath = workspacePath
        this.embedder = embedder
        this.vectorStore = vectorStore
    }

    async scanAndIndex(onProgress?: (progress: ScanProgress) => void): Promise<void> {
        // 1. æ‰«ææ‰€æœ‰ä»£ç æ–‡ä»¶
        const files = await this._scanCodeFiles()

        // 2. æ‰¹é‡å¤„ç†æ–‡ä»¶
        const batchBlocks: CodeBlock[] = []
        let processedCount = 0

        for (const filePath of files) {
            try {
                // è§£ææ–‡ä»¶å†…å®¹
                const blocks = await this._parseCodeFile(filePath)
                batchBlocks.push(...blocks)

                // è¾¾åˆ°æ‰¹æ¬¡å¤§å°æ—¶å¤„ç†
                if (batchBlocks.length >= this.batchSize) {
                    await this._processBatch(batchBlocks.splice(0, this.batchSize))
                    processedCount += this.batchSize

                    onProgress?.({
                        processedFiles: processedCount,
                        totalFiles: files.length,
                        currentFile: filePath
                    })
                }
            } catch (error) {
                console.error(`Failed to process file ${filePath}:`, error)
            }
        }

        // å¤„ç†å‰©ä½™çš„å—
        if (batchBlocks.length > 0) {
            await this._processBatch(batchBlocks)
        }
    }

    private async _scanCodeFiles(): Promise<string[]> {
        const glob = require("glob")
        const patterns = [
            "**/*.{js,jsx,ts,tsx}",
            "**/*.{py,pyx}",
            "**/*.{go,mod}",
            "**/*.{rs,toml}",
            "**/*.{java,kt,scala}",
            "**/*.{c,cpp,h,hpp}",
            "**/*.{php,rb,swift}",
        ]

        const files: string[] = []
        for (const pattern of patterns) {
            const matches = glob.sync(pattern, {
                cwd: this.workspacePath,
                ignore: [
                    "**/node_modules/**",
                    "**/dist/**",
                    "**/build/**",
                    "**/.git/**",
                    "**/target/**",
                ]
            })
            files.push(...matches.map(f => path.join(this.workspacePath, f)))
        }

        return files
    }

    private async _parseCodeFile(filePath: string): Promise<CodeBlock[]> {
        const content = await fs.readFile(filePath, "utf-8")
        const ext = path.extname(filePath)

        // ä½¿ç”¨Tree-sitterè§£æä»£ç 
        const parser = this._getParserForExtension(ext)
        if (!parser) {
            // å›é€€åˆ°ç®€å•åˆ†å—
            return this._simpleChunking(content, filePath)
        }

        const tree = parser.parse(content)
        return this._extractCodeBlocks(tree, content, filePath)
    }

    private async _processBatch(blocks: CodeBlock[]): Promise<void> {
        // 1. ç”Ÿæˆembeddings
        const texts = blocks.map(block => block.content)
        const { embeddings } = await this.embedder.createEmbeddings(texts)

        // 2. å‡†å¤‡å‘é‡æ•°æ®ç‚¹
        const points = blocks.map((block, index) => {
            const pointId = uuidv5(block.segmentHash, "6ba7b810-9dad-11d1-80b4-00c04fd430c8")

            return {
                id: pointId,
                vector: embeddings[index],
                payload: {
                    filePath: path.relative(this.workspacePath, block.filePath),
                    codeChunk: block.content,
                    startLine: block.startLine,
                    endLine: block.endLine,
                    segmentHash: block.segmentHash,
                    language: this._detectLanguage(block.filePath),
                }
            }
        })

        // 3. æ‰¹é‡ä¸Šä¼ åˆ°Qdrant
        await this.vectorStore.upsertPoints(points)
    }
}
```

### 4. æ–‡ä»¶ç›‘æ§å’Œå¢é‡æ›´æ–°

```typescript
export class FileWatcher {
    private watcher: chokidar.FSWatcher | null = null
    private scanner: CodeIndexScanner
    private debounceMap = new Map<string, NodeJS.Timeout>()

    constructor(scanner: CodeIndexScanner) {
        this.scanner = scanner
    }

    startWatching(workspacePath: string): void {
        this.watcher = chokidar.watch(workspacePath, {
            ignored: [
                "**/node_modules/**",
                "**/dist/**",
                "**/build/**",
                "**/.git/**",
            ],
            persistent: true,
            ignoreInitial: true,
        })

        this.watcher
            .on("add", (filePath) => this._handleFileChange(filePath, "add"))
            .on("change", (filePath) => this._handleFileChange(filePath, "change"))
            .on("unlink", (filePath) => this._handleFileDelete(filePath))
    }

    stopWatching(): void {
        if (this.watcher) {
            this.watcher.close()
            this.watcher = null
        }
    }

    private _handleFileChange(filePath: string, type: "add" | "change"): void {
        // é˜²æŠ–å¤„ç†
        if (this.debounceMap.has(filePath)) {
            clearTimeout(this.debounceMap.get(filePath)!)
        }

        const timeout = setTimeout(async () => {
            try {
                await this._processFileUpdate(filePath)
                this.debounceMap.delete(filePath)
            } catch (error) {
                console.error(`Failed to process file update ${filePath}:`, error)
            }
        }, 500) // 500msé˜²æŠ–

        this.debounceMap.set(filePath, timeout)
    }

    private async _handleFileDelete(filePath: string): Promise<void> {
        try {
            await this.scanner.vectorStore.deletePointsByFilePath(filePath)
        } catch (error) {
            console.error(`Failed to delete vectors for ${filePath}:`, error)
        }
    }

    private async _processFileUpdate(filePath: string): Promise<void> {
        // 1. åˆ é™¤æ—§çš„å‘é‡æ•°æ®
        await this.scanner.vectorStore.deletePointsByFilePath(filePath)

        // 2. é‡æ–°ç´¢å¼•æ–‡ä»¶
        const blocks = await this.scanner._parseCodeFile(filePath)
        if (blocks.length > 0) {
            await this.scanner._processBatch(blocks)
        }
    }
}
```

### 5. æœç´¢æœåŠ¡å®ç°

```typescript
export class CodeSearchService {
    private embedder: IEmbedder
    private vectorStore: IVectorStore

    constructor(embedder: IEmbedder, vectorStore: IVectorStore) {
        this.embedder = embedder
        this.vectorStore = vectorStore
    }

    async searchCode(
        query: string,
        options: SearchOptions = {}
    ): Promise<SearchResult[]> {
        const {
            directoryPrefix,
            maxResults = 20,
            minScore = 0.3,
            language
        } = options

        // 1. å°†æŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡
        const { embeddings } = await this.embedder.createEmbeddings([query])
        const queryVector = embeddings[0]

        // 2. æ‰§è¡Œå‘é‡æœç´¢
        const results = await this.vectorStore.search(
            queryVector,
            directoryPrefix,
            minScore,
            maxResults
        )

        // 3. æ ¼å¼åŒ–ç»“æœ
        return results.map(result => ({
            filePath: result.payload.filePath,
            codeChunk: result.payload.codeChunk,
            startLine: result.payload.startLine,
            endLine: result.payload.endLine,
            score: result.score,
            language: result.payload.language,
        }))
    }

    async searchSimilarCode(
        codeSnippet: string,
        options: SearchOptions = {}
    ): Promise<SearchResult[]> {
        // å¯¹ä»£ç ç‰‡æ®µè¿›è¡Œç›¸ä¼¼æ€§æœç´¢
        return this.searchCode(codeSnippet, options)
    }
}
```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºç¡€ä½¿ç”¨

```typescript
import { CodeVectorIndex } from "./code-vector-index"

async function main() {
    // 1. åˆå§‹åŒ–ç³»ç»Ÿ
    const codeIndex = new CodeVectorIndex({
        workspacePath: "/path/to/your/project",
        qdrantUrl: "http://localhost:6333",
        embedder: {
            provider: "openai",
            apiKey: "your-openai-api-key",
            model: "text-embedding-3-small"
        }
    })

    // 2. åˆå§‹åŒ–å‘é‡æ•°æ®åº“
    await codeIndex.initialize()

    // 3. æ‰«æå’Œç´¢å¼•ä»£ç 
    console.log("å¼€å§‹ç´¢å¼•ä»£ç ...")
    await codeIndex.scanAndIndex((progress) => {
        console.log(`è¿›åº¦: ${progress.processedFiles}/${progress.totalFiles}`)
    })

    // 4. å¯åŠ¨æ–‡ä»¶ç›‘æ§
    codeIndex.startWatching()

    // 5. æœç´¢ä»£ç 
    const results = await codeIndex.search("Reactç»„ä»¶çŠ¶æ€ç®¡ç†", {
        maxResults: 10,
        minScore: 0.4
    })

    console.log("æœç´¢ç»“æœ:", results)
}

main().catch(console.error)
```

### 2. é«˜çº§é…ç½®

```typescript
// å¤šæ¨¡å‹é…ç½®
const configs = [
    {
        provider: "openai",
        apiKey: process.env.OPENAI_API_KEY,
        model: "text-embedding-3-large"  // æ›´é«˜ç²¾åº¦
    },
    {
        provider: "ollama",
        baseUrl: "http://localhost:11434",
        model: "nomic-embed-code"  // ä»£ç ä¸“ç”¨æ¨¡å‹
    },
    {
        provider: "gemini",
        apiKey: process.env.GEMINI_API_KEY,
        model: "text-embedding-004"
    }
]

// Qdranté›†ç¾¤é…ç½®
const qdrantConfig = {
    url: "https://your-qdrant-cluster.com",
    apiKey: process.env.QDRANT_API_KEY,
    timeout: 30000,
    retries: 3
}
```

### 3. æœç´¢APIç¤ºä¾‹

```typescript
// åŸºç¡€æœç´¢
const basicResults = await codeIndex.search("æ•°æ®åº“è¿æ¥æ± ")

// ç›®å½•è¿‡æ»¤æœç´¢
const backendResults = await codeIndex.search("ç”¨æˆ·è®¤è¯", {
    directoryPrefix: "src/backend"
})

// è¯­è¨€è¿‡æ»¤æœç´¢
const pythonResults = await codeIndex.search("æœºå™¨å­¦ä¹ æ¨¡å‹", {
    language: "python",
    maxResults: 5
})

// ç›¸ä¼¼ä»£ç æœç´¢
const similarCode = await codeIndex.searchSimilarCode(`
function calculateTotal(items) {
    return items.reduce((sum, item) => sum + item.price, 0)
}
`)

// æ‰¹é‡æœç´¢
const queries = ["é”™è¯¯å¤„ç†", "æ€§èƒ½ä¼˜åŒ–", "å•å…ƒæµ‹è¯•"]
const batchResults = await Promise.all(
    queries.map(query => codeIndex.search(query))
)
```

### 4. é›†æˆåˆ°Webåº”ç”¨

```typescript
// Express.js APIç¤ºä¾‹
import express from "express"

const app = express()
const codeIndex = new CodeVectorIndex(config)

app.get("/api/search", async (req, res) => {
    try {
        const { query, directory, limit = 20 } = req.query

        const results = await codeIndex.search(query as string, {
            directoryPrefix: directory as string,
            maxResults: parseInt(limit as string)
        })

        res.json({
            success: true,
            results,
            total: results.length
        })
    } catch (error) {
        res.status(500).json({
            success: false,
            error: error.message
        })
    }
})

app.listen(3000, () => {
    console.log("ä»£ç æœç´¢APIå¯åŠ¨åœ¨ç«¯å£3000")
})
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ€§èƒ½ä¼˜åŒ–

#### æ‰¹å¤„ç†é…ç½®
```typescript
const optimizedConfig = {
    batchSize: 100,           // æ ¹æ®å†…å­˜è°ƒæ•´
    concurrency: 4,           // å¹¶å‘å¤„ç†æ•°
    maxPendingBatches: 3,     // æœ€å¤§å¾…å¤„ç†æ‰¹æ¬¡
    debounceMs: 1000,         // æ–‡ä»¶å˜åŒ–é˜²æŠ–
}
```

#### ç´¢å¼•ç­–ç•¥
```typescript
// å¢é‡ç´¢å¼• - åªå¤„ç†å˜åŒ–çš„æ–‡ä»¶
await codeIndex.incrementalIndex()

// å®šæœŸå…¨é‡é‡å»º - ä¿è¯æ•°æ®ä¸€è‡´æ€§
setInterval(async () => {
    await codeIndex.fullRebuild()
}, 24 * 60 * 60 * 1000) // æ¯24å°æ—¶
```

### 2. é”™è¯¯å¤„ç†

```typescript
class RobustCodeIndex extends CodeVectorIndex {
    async search(query: string, options: SearchOptions = {}) {
        const maxRetries = 3
        let lastError: Error

        for (let i = 0; i < maxRetries; i++) {
            try {
                return await super.search(query, options)
            } catch (error) {
                lastError = error
                console.warn(`æœç´¢é‡è¯• ${i + 1}/${maxRetries}:`, error.message)

                // æŒ‡æ•°é€€é¿
                await new Promise(resolve =>
                    setTimeout(resolve, Math.pow(2, i) * 1000)
                )
            }
        }

        throw lastError
    }
}
```

### 3. ç›‘æ§å’Œæ—¥å¿—

```typescript
// æ€§èƒ½ç›‘æ§
class MonitoredCodeIndex extends CodeVectorIndex {
    private metrics = {
        searchCount: 0,
        avgSearchTime: 0,
        indexedFiles: 0,
        errors: 0
    }

    async search(query: string, options?: SearchOptions) {
        const startTime = Date.now()

        try {
            const results = await super.search(query, options)

            // æ›´æ–°æŒ‡æ ‡
            this.metrics.searchCount++
            const searchTime = Date.now() - startTime
            this.metrics.avgSearchTime =
                (this.metrics.avgSearchTime + searchTime) / 2

            console.log(`æœç´¢å®Œæˆ: ${searchTime}ms, ç»“æœæ•°: ${results.length}`)
            return results
        } catch (error) {
            this.metrics.errors++
            throw error
        }
    }

    getMetrics() {
        return { ...this.metrics }
    }
}
```

### 4. é…ç½®ç®¡ç†

```typescript
// ç¯å¢ƒé…ç½®
const config = {
    development: {
        qdrantUrl: "http://localhost:6333",
        batchSize: 20,
        logLevel: "debug"
    },
    production: {
        qdrantUrl: process.env.QDRANT_URL,
        apiKey: process.env.QDRANT_API_KEY,
        batchSize: 100,
        logLevel: "info"
    }
}

const env = process.env.NODE_ENV || "development"
const currentConfig = config[env]
```

### 5. æ•°æ®å¤‡ä»½å’Œæ¢å¤

```typescript
// å¤‡ä»½å‘é‡æ•°æ®
async function backupVectorData(codeIndex: CodeVectorIndex) {
    const backup = await codeIndex.exportData()
    await fs.writeFile(
        `backup-${Date.now()}.json`,
        JSON.stringify(backup, null, 2)
    )
}

// æ¢å¤å‘é‡æ•°æ®
async function restoreVectorData(codeIndex: CodeVectorIndex, backupFile: string) {
    const backup = JSON.parse(await fs.readFile(backupFile, "utf-8"))
    await codeIndex.importData(backup)
}
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Qdrantè¿æ¥å¤±è´¥**
   ```bash
   # æ£€æŸ¥QdrantæœåŠ¡çŠ¶æ€
   curl http://localhost:6333/health

   # æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
   sudo ufw status
   ```

2. **å†…å­˜ä¸è¶³**
   ```typescript
   // å‡å°‘æ‰¹å¤„ç†å¤§å°
   const config = { batchSize: 20 }

   // å¯ç”¨ç£ç›˜å­˜å‚¨
   const qdrantConfig = { on_disk: true }
   ```

3. **ç´¢å¼•é€Ÿåº¦æ…¢**
   ```typescript
   // å¢åŠ å¹¶å‘æ•°
   const config = { concurrency: 8 }

   // ä½¿ç”¨æ›´å¿«çš„embeddingæ¨¡å‹
   const embedder = { model: "text-embedding-3-small" }
   ```

## ğŸ“š å‚è€ƒèµ„æº

- [Qdrantå®˜æ–¹æ–‡æ¡£](https://qdrant.tech/documentation/)
- [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings)
- [Tree-sitteræ–‡æ¡£](https://tree-sitter.github.io/tree-sitter/)
- [å‘é‡æœç´¢æœ€ä½³å®è·µ](https://www.pinecone.io/learn/vector-search/)

---

**å®Œæ•´å®ç°åŸºäºRoo Codeé¡¹ç›®ï¼Œç»è¿‡ç”Ÿäº§ç¯å¢ƒéªŒè¯ï¼Œå¯ç›´æ¥ç”¨äºæ‚¨çš„é¡¹ç›®ä¸­ï¼**
