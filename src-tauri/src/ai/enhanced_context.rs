/*!
 * æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿ - åŸºäºClaude Codeé€†å‘åˆ†æä¼˜åŒ–
 *
 * æ ¸å¿ƒç‰¹æ€§ï¼š
 * 1. 92%è§¦å‘é˜ˆå€¼çš„æ™ºèƒ½å‹ç¼© (å‚è€ƒClaude Codeå®ç°)
 * 2. 30%ä¸Šä¸‹æ–‡ä¿ç•™ç‡ä¸é‡è¦æ€§è¯„åˆ†
 * 3. é«˜æ•ˆKVç¼“å­˜ä¸è¯­ä¹‰ç›¸ä¼¼æ€§åŒ¹é…
 * 4. åˆ†å±‚å‹ç¼©ç­–ç•¥ï¼šè½»é‡çº§ -> æ·±åº¦å‹ç¼©
 */

use crate::ai::types::Message;
use crate::storage::repositories::RepositoryManager;
use crate::utils::error::AppResult;
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use tracing::{debug, info};

// ============= é…ç½®å±‚ =============

/// ä¸Šä¸‹æ–‡ç®¡ç†é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContextConfig {
    /// æœ€å¤§tokenæ•°é‡
    pub max_tokens: usize,
    /// å‹ç¼©è§¦å‘é˜ˆå€¼(0.0-1.0)
    pub compress_threshold: f32,
    /// ä¿ç•™æœ€è¿‘æ¶ˆæ¯æ•°
    pub keep_recent: usize,
    /// ä¿ç•™é‡è¦æ¶ˆæ¯æ•°
    pub keep_important: usize,
    /// æœ€å°å‹ç¼©æ‰¹æ¬¡å¤§å°
    pub min_compress_batch: usize,
    /// æ‘˜è¦çª—å£å¤§å°
    pub summary_window_size: usize,
    /// é‡è¦æ€§é˜ˆå€¼
    pub importance_threshold: f32,
    /// KVç¼“å­˜é…ç½®
    pub kv_cache: KVCacheConfig,
}

/// KVç¼“å­˜é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct KVCacheConfig {
    /// æ˜¯å¦å¯ç”¨KVç¼“å­˜
    pub enabled: bool,
    /// ç¼“å­˜TTLï¼ˆç§’ï¼‰
    pub ttl_seconds: u64,
    /// æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
    pub max_entries: usize,
    /// ç¨³å®šå‰ç¼€æœ€å¤§é•¿åº¦
    pub stable_prefix_max_tokens: usize,
}

impl Default for KVCacheConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            ttl_seconds: 3600, // 1å°æ—¶
            max_entries: 100,
            stable_prefix_max_tokens: 1000,
        }
    }
}

impl Default for ContextConfig {
    fn default() -> Self {
        Self {
            max_tokens: 100000,   
            compress_threshold: 0.92, // 92%è§¦å‘é˜ˆå€¼ (Claude Codeæ ‡å‡†)
            keep_recent: 12,      // ä¿ç•™æœ€è¿‘12æ¡æ¶ˆæ¯
            keep_important: 8,    // é‡è¦æ¶ˆæ¯æ•°é‡ä¼˜åŒ–
            min_compress_batch: 3, // å‡å°‘æœ€å°æ‰¹æ¬¡
            summary_window_size: 8, // ä¼˜åŒ–çª—å£å¤§å°
            importance_threshold: 0.7, // æé«˜é‡è¦æ€§é˜ˆå€¼
            kv_cache: KVCacheConfig::default(),
        }
    }
}

// ============= KVç¼“å­˜å±‚ =============

/// KVç¼“å­˜é¡¹
#[derive(Debug, Clone)]
pub struct CacheEntry {
    /// ç¼“å­˜çš„ä¸Šä¸‹æ–‡å†…å®¹
    pub content: String,
    /// æ¶ˆæ¯åˆ—è¡¨çš„å“ˆå¸Œå€¼
    pub messages_hash: u64,
    /// åˆ›å»ºæ—¶é—´
    pub created_at: DateTime<Utc>,
    /// æœ€åè®¿é—®æ—¶é—´
    pub last_accessed: DateTime<Utc>,
    /// å‘½ä¸­æ¬¡æ•°
    pub hit_count: u64,
    /// ç¨³å®šå‰ç¼€é•¿åº¦
    pub stable_prefix_len: usize,
    /// è¯­ä¹‰å“ˆå¸Œï¼ˆåŸºäºæ¶ˆæ¯è¯­ä¹‰è€Œéç®€å•æ–‡æœ¬ï¼‰
    pub semantic_hash: u64,
    /// è®¿é—®é¢‘ç‡æƒé‡
    pub access_weight: f64,
}

/// KVç¼“å­˜ç®¡ç†å™¨ - åŸºäºManusåŸç†
pub struct KVCache {
    /// ç¼“å­˜å­˜å‚¨
    cache: Arc<Mutex<HashMap<String, CacheEntry>>>,
    /// é…ç½®
    config: KVCacheConfig,
}

impl KVCache {
    pub fn new(config: KVCacheConfig) -> Self {
        Self {
            cache: Arc::new(Mutex::new(HashMap::new())),
            config,
        }
    }

    /// ç”Ÿæˆç¼“å­˜é”® - åŸºäºå¯¹è¯IDå’Œå‰ç¼€å“ˆå¸Œ
    fn generate_cache_key(&self, conv_id: i64, prefix_hash: u64) -> String {
        format!("ctx_{}_{}", conv_id, prefix_hash)
    }

    /// è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„å“ˆå¸Œå€¼ï¼ˆç»“æ„åŒ–å“ˆå¸Œï¼‰
    fn hash_messages(&self, msgs: &[Message]) -> u64 {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        for msg in msgs {
            msg.id.hash(&mut hasher);
            msg.role.hash(&mut hasher);
            // å¯¹å†…å®¹è¿›è¡Œè§„èŒƒåŒ–å¤„ç†ï¼Œå¿½ç•¥ç©ºç™½å­—ç¬¦å·®å¼‚
            msg.content.trim().hash(&mut hasher);
            // å“ˆå¸Œå·¥å…·è°ƒç”¨ä¿¡æ¯
            if let Some(ref steps) = msg.steps_json {
                steps.hash(&mut hasher);
            }
        }
        hasher.finish()
    }


    /// æ™ºèƒ½æå–ç¨³å®šå‰ç¼€ - è€ƒè™‘è¯­ä¹‰è¾¹ç•Œ
    pub fn extract_stable_prefix(&self, msgs: &[Message]) -> Vec<Message> {
        if msgs.is_empty() {
            return Vec::new();
        }

        let mut stable_msgs = Vec::new();
        let mut token_count = 0;
        let mut last_system_index = None;

        // é¦–å…ˆæ‰¾åˆ°æœ€åä¸€ä¸ªç³»ç»Ÿæ¶ˆæ¯ä½ç½®ä½œä¸ºæ½œåœ¨è¾¹ç•Œ
        for (i, msg) in msgs.iter().enumerate() {
            if msg.role == "system" {
                last_system_index = Some(i);
            }
        }

        // ä¼˜å…ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæ—©æœŸå¯¹è¯å»ºç«‹ä¸Šä¸‹æ–‡
        for (i, msg) in msgs.iter().enumerate() {
            let msg_tokens = self.estimate_message_tokens(msg);
            
            // å¦‚æœè¶…å‡ºtokené™åˆ¶ï¼Œæ£€æŸ¥æ˜¯å¦åœ¨è¯­ä¹‰è¾¹ç•Œ
            if token_count + msg_tokens > self.config.stable_prefix_max_tokens {
                // å¦‚æœå½“å‰ä½ç½®æ¥è¿‘ç³»ç»Ÿæ¶ˆæ¯è¾¹ç•Œï¼Œç»§ç»­åˆ°ç³»ç»Ÿæ¶ˆæ¯
                if let Some(sys_idx) = last_system_index {
                    if i <= sys_idx + 2 && token_count < self.config.stable_prefix_max_tokens * 2 {
                        // å…è®¸é€‚åº¦è¶…å‡ºä»¥ä¿æŒè¯­ä¹‰å®Œæ•´æ€§
                    } else {
                        break;
                    }
                } else {
                    break;
                }
            }

            stable_msgs.push(msg.clone());
            token_count += msg_tokens;

            // å¦‚æœå·²ç»åŒ…å«äº†ç³»ç»Ÿæ¶ˆæ¯åŠå…¶åç»­2-3æ¡æ¶ˆæ¯ï¼Œè€ƒè™‘åœæ­¢
            if let Some(sys_idx) = last_system_index {
                if i > sys_idx + 3 && token_count > self.config.stable_prefix_max_tokens / 2 {
                    break;
                }
            }
        }

        debug!(
            "æå–ç¨³å®šå‰ç¼€: {} -> {} æ¡æ¶ˆæ¯, {} tokens", 
            msgs.len(), stable_msgs.len(), token_count
        );

        stable_msgs
    }

    /// æ›´å‡†ç¡®çš„tokenä¼°ç®—
    fn estimate_message_tokens(&self, msg: &Message) -> usize {
        let content_tokens = msg.content.len() / 3; // ä¸­è‹±æ··åˆï¼Œ3å­—ç¬¦çº¦1token
        let steps_tokens = msg.steps_json.as_ref()
            .map(|s| s.len() / 4)
            .unwrap_or(0);
        content_tokens + steps_tokens
    }

    /// é«˜æ•ˆç¼“å­˜è·å– - ç²¾ç¡®åŒ¹é…ä¼˜å…ˆ
    pub fn get(&self, conv_id: i64, msgs: &[Message]) -> Option<String> {
        if !self.config.enabled || msgs.is_empty() {
            return None;
        }

        let stable_prefix = self.extract_stable_prefix(msgs);
        let prefix_hash = self.hash_messages(&stable_prefix);
        let cache_key = self.generate_cache_key(conv_id, prefix_hash);

        let mut cache = self.cache.lock().ok()?;

        if let Some(entry) = cache.get_mut(&cache_key) {
            if self.is_entry_valid(entry) {
                self.update_entry_access(entry);
                debug!("ç¼“å­˜å‘½ä¸­: {} (hits: {})", cache_key, entry.hit_count);
                return Some(entry.content.clone());
            } else {
                cache.remove(&cache_key);
                debug!("æ¸…ç†è¿‡æœŸç¼“å­˜: {}", cache_key);
            }
        }

        debug!("ç¼“å­˜æœªå‘½ä¸­: {}", cache_key);
        None
    }

    /// æ£€æŸ¥ç¼“å­˜æ¡ç›®æ˜¯å¦æœ‰æ•ˆï¼ˆTTLå’Œå…¶ä»–æ¡ä»¶ï¼‰
    fn is_entry_valid(&self, entry: &CacheEntry) -> bool {
        let now = Utc::now();
        let elapsed = now.signed_duration_since(entry.created_at).num_seconds();
        elapsed >= 0 && (elapsed as u64) <= self.config.ttl_seconds
    }

    /// æ›´æ–°ç¼“å­˜æ¡ç›®çš„è®¿é—®ä¿¡æ¯
    fn update_entry_access(&self, entry: &mut CacheEntry) {
        let now = Utc::now();
        entry.hit_count += 1;
        entry.last_accessed = now;
        
        // åŠ¨æ€è°ƒæ•´è®¿é—®æƒé‡ï¼šæœ€è¿‘è®¿é—® + é¢‘ç‡
        let recency_weight = 1.0 / (1.0 + (now.signed_duration_since(entry.last_accessed).num_minutes() as f64 / 60.0));
        let frequency_weight = (entry.hit_count as f64).ln() / 10.0;
        entry.access_weight = recency_weight + frequency_weight;
    }


    /// é«˜æ•ˆç¼“å­˜å­˜å‚¨ - ç®€åŒ–çš„LRUæœºåˆ¶
    pub fn put(&self, conv_id: i64, msgs: &[Message], content: String) {
        if !self.config.enabled || msgs.is_empty() {
            return;
        }

        let stable_prefix = self.extract_stable_prefix(msgs);
        let prefix_hash = self.hash_messages(&stable_prefix);
        let cache_key = self.generate_cache_key(conv_id, prefix_hash);
        let messages_hash = self.hash_messages(msgs);

        let mut cache = self.cache.lock().unwrap();

        // ç®€åŒ–çš„ç¼“å­˜ç©ºé—´ç®¡ç†
        if cache.len() >= self.config.max_entries {
            let oldest_key = cache.iter()
                .min_by_key(|(_, entry)| entry.last_accessed)
                .map(|(k, _)| k.clone());
            if let Some(key) = oldest_key {
                cache.remove(&key);
                debug!("LRUæ¸…ç†ç¼“å­˜: {}", key);
            }
        }

        let now = Utc::now();
        let entry = CacheEntry {
            content,
            messages_hash,
            created_at: now,
            last_accessed: now,
            hit_count: 0,
            stable_prefix_len: stable_prefix.len(),
            semantic_hash: 0, // ç®€åŒ–ï¼Œä¸ä½¿ç”¨è¯­ä¹‰å“ˆå¸Œ
            access_weight: 1.0,
        };

        cache.insert(cache_key.clone(), entry);
        debug!("ç¼“å­˜å­˜å‚¨: {}", cache_key);
    }


    /// è·å–ç¼“å­˜ç»Ÿè®¡
    pub fn stats(&self) -> CacheStats {
        let cache = self.cache.lock().unwrap();
        let total_hits: u64 = cache.values().map(|e| e.hit_count).sum();
        let total_entries = cache.len();

        CacheStats {
            total_entries,
            total_hits,
            hit_rate: if total_entries > 0 {
                total_hits as f64 / (total_entries as f64 + total_hits as f64)
            } else {
                0.0
            },
        }
    }

    /// æ¸…ç†è¿‡æœŸç¼“å­˜
    pub fn cleanup_expired(&self) {
        let mut cache = self.cache.lock().unwrap();
        let now = Utc::now();

        cache.retain(|key, entry| {
            let elapsed = now.signed_duration_since(entry.created_at).num_seconds();
            if elapsed as u64 > self.config.ttl_seconds {
                debug!("æ¸…ç†è¿‡æœŸç¼“å­˜: {}", key);
                false
            } else {
                true
            }
        });
    }
}

/// ç¼“å­˜ç»Ÿè®¡
#[derive(Debug, Clone)]
pub struct CacheStats {
    pub total_entries: usize,
    pub total_hits: u64,
    pub hit_rate: f64,
}

// ============= ç­–ç•¥å±‚ =============

/// å‹ç¼©ç­–ç•¥ç‰¹å¾
pub trait CompressionStrategy: Send + Sync {
    fn compress(&self, msgs: &[Message], config: &ContextConfig) -> AppResult<Vec<Message>>;
}

/// é«˜æ•ˆå‹ç¼©ç­–ç•¥ - åŸºäºClaude Codeçš„30%ä¿ç•™ç‡å®ç°
pub struct EfficientCompressionStrategy;

/// æ¶ˆæ¯é‡è¦æ€§è¯„ä¼°
#[derive(Debug, Clone)]
struct MessageImportance {
    pub index: usize,
    pub message: Message,
    pub importance_score: f64,
    pub is_tool_execution: bool,
    pub is_system: bool,
}

impl CompressionStrategy for EfficientCompressionStrategy {
    fn compress(&self, msgs: &[Message], config: &ContextConfig) -> AppResult<Vec<Message>> {
        if msgs.len() < config.min_compress_batch {
            debug!("æ¶ˆæ¯æ•°é‡ä¸è¶³ï¼Œè·³è¿‡å‹ç¼©: {}", msgs.len());
            return Ok(msgs.to_vec());
        }

        debug!("å¼€å§‹é«˜æ•ˆå‹ç¼©: {} æ¡æ¶ˆæ¯", msgs.len());

        // è®¡ç®—30%ä¿ç•™ç›®æ ‡æ•°é‡ (Claude Codeæ ‡å‡†)
        let target_count = (msgs.len() as f64 * 0.30).max(config.min_compress_batch as f64) as usize;
        
        // 1. åˆ†ææ¶ˆæ¯é‡è¦æ€§
        let importance_analysis = self.analyze_message_importance(msgs);
        
        // 2. åº”ç”¨ä¿ç•™ç­–ç•¥
        let preserved_messages = self.apply_retention_strategy(importance_analysis, target_count, config)?;

        // 3. æœ€ç»ˆæ’åºå’Œå»é‡
        self.finalize_result(preserved_messages, msgs.len())
    }
}

impl EfficientCompressionStrategy {
    /// å¿«é€Ÿé‡è¦æ€§åˆ†æ
    fn analyze_message_importance(&self, msgs: &[Message]) -> Vec<MessageImportance> {
        let scorer = AdvancedMessageScorer::new();
        
        msgs.iter()
            .enumerate()
            .map(|(index, msg)| {
                let importance_score = scorer.compute_comprehensive_score(msg, index, msgs.len());
                
                MessageImportance {
                    index,
                    message: msg.clone(),
                    importance_score,
                    is_tool_execution: msg.steps_json.is_some(),
                    is_system: msg.role == "system",
                }
            })
            .collect()
    }

    /// é«˜æ•ˆä¿ç•™ç­–ç•¥ - åŸºäº30%ç›®æ ‡
    fn apply_retention_strategy(&self, mut analysis: Vec<MessageImportance>, target_count: usize, config: &ContextConfig) -> AppResult<Vec<MessageImportance>> {
        let mut result = Vec::new();

        // 1. å¼ºåˆ¶ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
        for item in &analysis {
            if item.is_system {
                result.push(item.clone());
            }
        }

        // 2. ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯ï¼ˆä¿è¯è¿ç»­æ€§ï¼‰
        let recent_start = analysis.len().saturating_sub(config.keep_recent);
        for item in &analysis[recent_start..] {
            if !item.is_system && !result.iter().any(|r| r.index == item.index) {
                result.push(item.clone());
            }
        }

        // 3. å¦‚æœè¿˜éœ€è¦æ›´å¤šæ¶ˆæ¯ï¼ŒæŒ‰é‡è¦æ€§é€‰æ‹©
        if result.len() < target_count {
            analysis.sort_by(|a, b| b.importance_score.partial_cmp(&a.importance_score).unwrap_or(std::cmp::Ordering::Equal));
            
            let needed = target_count - result.len();
            for item in analysis.iter().take(needed * 2) {
                if result.len() >= target_count { break; }
                if !result.iter().any(|r| r.index == item.index) {
                    result.push(item.clone());
                }
            }
        }

        // æ’åºå’Œå»é‡
        result.sort_by_key(|m| m.index);
        result.dedup_by_key(|m| m.message.id);

        debug!("ä¿ç•™ç­–ç•¥ç»“æœ: {} -> {} æ¡æ¶ˆæ¯", analysis.len(), result.len());
        Ok(result)
    }

    /// æœ€ç»ˆç»“æœå¤„ç†
    fn finalize_result(&self, mut messages: Vec<MessageImportance>, original_count: usize) -> AppResult<Vec<Message>> {
        // æŒ‰æ—¶é—´é¡ºåºæ’åº
        messages.sort_by_key(|m| m.index);
        
        let result: Vec<Message> = messages.into_iter().map(|m| m.message).collect();
        let compression_rate = (1.0 - result.len() as f64 / original_count as f64) * 100.0;

        debug!(
            "é«˜æ•ˆå‹ç¼©å®Œæˆ: {} -> {} æ¡æ¶ˆæ¯ (å‹ç¼©ç‡: {:.1}%)",
            original_count, result.len(), compression_rate
        );

        Ok(result)
    }
}

/// å¾ªç¯æ£€æµ‹ç­–ç•¥
pub struct LoopDetector {
    window_size: usize,
}

impl LoopDetector {
    pub fn new(window_size: usize) -> Self {
        Self { window_size }
    }

    pub fn remove_loops(&self, msgs: Vec<Message>) -> Vec<Message> {
        let mut result = Vec::new();
        let mut seen_hashes = HashMap::new();

        for (idx, msg) in msgs.into_iter().enumerate() {
            let hash = self.content_hash(&msg.content);

            if let Some(&last_idx) = seen_hashes.get(&hash) {
                if idx - last_idx <= self.window_size {
                    debug!("è·³è¿‡å¾ªç¯æ¶ˆæ¯: {:?}", msg.id);
                    continue;
                }
            }

            seen_hashes.insert(hash, idx);
            result.push(msg);
        }

        result
    }

    fn content_hash(&self, content: &str) -> u64 {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        content.hash(&mut hasher);
        hasher.finish()
    }
}

// ============= è¯„åˆ†å±‚ =============

/// é«˜çº§æ¶ˆæ¯è¯„åˆ†å™¨ - å¤šç»´åº¦è¯„åˆ†
pub struct AdvancedMessageScorer {
    keyword_weights: HashMap<&'static str, f32>,
    semantic_weights: HashMap<&'static str, f32>,
}

/// ç®€å•æ¶ˆæ¯è¯„åˆ†å™¨ï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼‰
pub struct MessageScorer {
    keyword_weights: HashMap<&'static str, f32>,
}

impl AdvancedMessageScorer {
    pub fn new() -> Self {
        let mut keyword_weights = HashMap::new();
        keyword_weights.insert("error", 3.0);
        keyword_weights.insert("warning", 2.5);
        keyword_weights.insert("failed", 2.8);
        keyword_weights.insert("success", 2.0);
        keyword_weights.insert("config", 1.8);
        keyword_weights.insert("install", 1.6);
        keyword_weights.insert("debug", 1.4);
        keyword_weights.insert("important", 2.2);
        keyword_weights.insert("critical", 3.2);

        let mut semantic_weights = HashMap::new();
        semantic_weights.insert("question", 1.5);
        semantic_weights.insert("solution", 2.0);
        semantic_weights.insert("problem", 1.8);
        semantic_weights.insert("implement", 1.6);
        semantic_weights.insert("fix", 2.2);
        semantic_weights.insert("optimize", 1.7);

        Self {
            keyword_weights,
            semantic_weights,
        }
    }

    /// è®¡ç®—ç»¼åˆé‡è¦æ€§è¯„åˆ†
    pub fn compute_comprehensive_score(&self, msg: &Message, index: usize, total_msgs: usize) -> f64 {
        let mut score = 0.0;

        // 1. åŸºç¡€è§’è‰²æƒé‡
        score += match msg.role.as_str() {
            "system" => 4.0,
            "assistant" => 1.8,
            "user" => 1.2,
            _ => 0.8,
        };

        // 2. å·¥å…·æ‰§è¡Œé«˜æƒé‡ï¼ˆç¡®ä¿ä¿ç•™é‡è¦æ‰§è¡Œç»“æœï¼‰
        if msg.steps_json.is_some() {
            score += self.evaluate_tool_execution_importance(msg);
        }

        // 3. å†…å®¹è¯­ä¹‰è¯„åˆ†
        score += self.evaluate_content_semantics(&msg.content);

        // 4. ä½ç½®æƒé‡ï¼ˆæœ€è¿‘å’Œæœ€æ—©çš„æ¶ˆæ¯æ›´é‡è¦ï¼‰
        let position_weight = self.compute_position_weight(index, total_msgs);
        score *= position_weight;

        // 5. å†…å®¹é•¿åº¦è¯„åˆ†ï¼ˆé€‚ä¸­é•¿åº¦æœ€ä¼˜ï¼‰
        score += self.evaluate_content_length(&msg.content);

        // 6. æ—¶é—´è¡°å‡ï¼ˆè¾ƒæ–°çš„æ¶ˆæ¯æƒé‡æ›´é«˜ï¼‰
        score *= self.compute_time_decay(msg);

        // 7. å¯¹è¯è¿ç»­æ€§è¯„åˆ†ï¼ˆè€ƒè™‘ä¸Šä¸‹æ–‡å…³è”ï¼‰
        score += self.evaluate_conversational_continuity(msg);

        score.max(0.0).min(10.0)
    }

    /// è¯„ä¼°å·¥å…·æ‰§è¡Œé‡è¦æ€§
    fn evaluate_tool_execution_importance(&self, msg: &Message) -> f64 {
        let base_score = 4.0; // å·¥å…·æ‰§è¡ŒåŸºç¡€é«˜åˆ†

        if let Some(ref steps_json) = msg.steps_json {
            // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if steps_json.contains("ToolError") || steps_json.contains("failed") {
                return base_score + 2.0; // é”™è¯¯ä¿¡æ¯å¾ˆé‡è¦
            }

            // æ£€æŸ¥å·¥å…·ç±»å‹é‡è¦æ€§
            if steps_json.contains("Read") || steps_json.contains("Write") || steps_json.contains("Edit") {
                return base_score + 1.5; // æ–‡ä»¶æ“ä½œé‡è¦
            }

            if steps_json.contains("Bash") || steps_json.contains("Execute") {
                return base_score + 1.0; // å‘½ä»¤æ‰§è¡Œé‡è¦
            }
        }

        base_score
    }

    /// è¯„ä¼°å†…å®¹è¯­ä¹‰
    fn evaluate_content_semantics(&self, content: &str) -> f64 {
        let mut score = 0.0f64;
        let content_lower = content.to_lowercase();

        // å…³é”®è¯æƒé‡
        for (&keyword, &weight) in &self.keyword_weights {
            if content_lower.contains(keyword) {
                score += weight as f64;
            }
        }

        // è¯­ä¹‰æ¨¡å¼æƒé‡
        for (&pattern, &weight) in &self.semantic_weights {
            if content_lower.contains(pattern) {
                score += weight as f64;
            }
        }

        // é—®å·è¡¨ç¤ºé—®é¢˜ï¼Œé‡è¦æ€§è¾ƒé«˜
        let question_count = content.matches('?').count() as f64;
        score += question_count * 0.5;

        // ä»£ç å—è¡¨ç¤ºæŠ€æœ¯å†…å®¹ï¼Œé€‚åº¦åŠ åˆ†
        let code_block_count = content.matches("```").count() as f64 / 2.0;
        score += code_block_count * 0.8;

        score
    }

    /// è®¡ç®—ä½ç½®æƒé‡
    fn compute_position_weight(&self, index: usize, total_msgs: usize) -> f64 {
        if total_msgs <= 1 {
            return 1.0;
        }

        let relative_position = index as f64 / (total_msgs - 1) as f64;

        // æœ€è¿‘çš„æ¶ˆæ¯æƒé‡æœ€é«˜ï¼Œæœ€æ—©çš„æ¶ˆæ¯ä¹Ÿæœ‰ä¸€å®šæƒé‡
        if relative_position > 0.8 {
            1.4 // æœ€è¿‘20%çš„æ¶ˆæ¯
        } else if relative_position < 0.2 {
            1.2 // æœ€æ—©20%çš„æ¶ˆæ¯
        } else {
            1.0 // ä¸­é—´æ¶ˆæ¯æ­£å¸¸æƒé‡
        }
    }

    /// è¯„ä¼°å†…å®¹é•¿åº¦
    fn evaluate_content_length(&self, content: &str) -> f64 {
        match content.len() {
            0..=20 => 0.3,      // å¤ªçŸ­ï¼Œä¿¡æ¯é‡å°‘
            21..=100 => 1.2,    // é€‚ä¸­ï¼Œä¿¡æ¯å¯†åº¦é«˜
            101..=300 => 1.5,   // è¾ƒé•¿ï¼Œä¿¡æ¯ä¸°å¯Œ
            301..=800 => 1.0,   // å¾ˆé•¿ï¼Œå¯èƒ½æœ‰å†—ä½™
            _ => 0.6,           // è¿‡é•¿ï¼Œå¯èƒ½ä¿¡æ¯å†—ä½™
        }
    }

    /// è®¡ç®—æ—¶é—´è¡°å‡
    fn compute_time_decay(&self, msg: &Message) -> f64 {
        let created_at = chrono::DateTime::parse_from_rfc3339(&msg.created_at)
            .map(|dt| dt.with_timezone(&chrono::Utc))
            .unwrap_or_else(|_| chrono::Utc::now());
        
        let hours_ago = chrono::Utc::now()
            .signed_duration_since(created_at)
            .num_hours() as f64;

        // 48å°æ—¶åŠè¡°æœŸï¼Œä½†æœ€ä½ä¿æŒ30%æƒé‡
        let decay_factor = (-hours_ago / 48.0).exp();
        decay_factor.max(0.3)
    }

    /// è¯„ä¼°å¯¹è¯è¿ç»­æ€§
    fn evaluate_conversational_continuity(&self, msg: &Message) -> f64 {
        let mut score = 0.0;

        // å›å¤æŒ‡ç¤ºè¯åŠ åˆ†
        let content_lower = msg.content.to_lowercase();
        if content_lower.contains("thanks") || content_lower.contains("thank you") {
            score += 0.5;
        }

        if content_lower.contains("please") || content_lower.contains("help") {
            score += 0.8;
        }

        // ç¡®è®¤æˆ–å¦å®šè¯æ±‡
        if content_lower.contains("yes") || content_lower.contains("no") 
            || content_lower.contains("ok") || content_lower.contains("sure") {
            score += 0.3;
        }

        score
    }
}

impl MessageScorer {
    pub fn new() -> Self {
        let mut weights = HashMap::new();
        weights.insert("error", 2.0);
        weights.insert("warning", 1.5);
        weights.insert("config", 1.3);
        weights.insert("install", 1.2);
        weights.insert("debug", 1.1);

        Self {
            keyword_weights: weights,
        }
    }

    pub fn score(&self, msg: &Message) -> f32 {
        let mut score = 0.0;

        // åŸºç¡€åˆ†ï¼šè§’è‰²æƒé‡
        score += match msg.role.as_str() {
            "system" => 3.0,
            "assistant" => 1.5,
            "user" => 1.0,
            _ => 0.5,
        };

        // å·¥å…·è°ƒç”¨åŠ åˆ†ï¼ˆå¤§å¹…æé«˜åˆ†æ•°ï¼Œç¡®ä¿é‡è¦å·¥å…·ç»“æœä¸è¢«ä¸¢å¤±ï¼‰
        if msg.steps_json.is_some() {
            score += 5.0; // ä»2.0æé«˜åˆ°5.0ï¼Œç¡®ä¿å·¥å…·æ‰§è¡Œæ¶ˆæ¯ä¼˜å…ˆä¿ç•™
        }

        // é•¿åº¦åˆ† (é€‚ä¸­é•¿åº¦å¾—åˆ†é«˜)
        let len_score = match msg.content.len() {
            0..=50 => 0.5,
            51..=200 => 1.5,
            201..=500 => 2.0,
            501..=1000 => 1.0,
            _ => 0.5,
        };
        score += len_score;

        // å…³é”®è¯åˆ†
        let content_lower = msg.content.to_lowercase();
        for (&keyword, &weight) in &self.keyword_weights {
            if content_lower.contains(keyword) {
                score += weight;
            }
        }

        // æ—¶é—´è¡°å‡ (24å°æ—¶åŠè¡°æœŸ)
        let created_at = chrono::DateTime::parse_from_rfc3339(&msg.created_at)
            .map(|dt| dt.with_timezone(&chrono::Utc))
            .unwrap_or_else(|_| chrono::Utc::now());
        let hours = chrono::Utc::now()
            .signed_duration_since(created_at)
            .num_hours() as f32;
        score *= (-hours / 24.0).exp();

        score.max(0.0).min(10.0)
    }
}

// ============= ç®¡ç†å±‚ =============

/// å‹ç¼©å†³ç­–ç±»å‹
#[derive(Debug, Clone, PartialEq)]
enum CompressionDecision {
    /// æ— éœ€å‹ç¼©
    NoCompression,
    /// è½»é‡å‹ç¼©ï¼ˆå»é™¤å†—ä½™ï¼Œä¿ç•™æ ¸å¿ƒï¼‰
    LightCompression,
    /// æ·±åº¦å‹ç¼©ï¼ˆä½¿ç”¨æ™ºèƒ½ç­–ç•¥å¤§å¹…å‹ç¼©ï¼‰
    HeavyCompression,
}

/// æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - ä¸»è¦å…¥å£
pub struct ContextManager {
    config: ContextConfig,
    strategy: Box<dyn CompressionStrategy>,
    loop_detector: LoopDetector,
    kv_cache: KVCache,
}

impl ContextManager {
    pub fn new(config: ContextConfig) -> Self {
        let kv_cache = KVCache::new(config.kv_cache.clone());
        Self {
            loop_detector: LoopDetector::new(6), // ä¼˜åŒ–å¾ªç¯æ£€æµ‹çª—å£
            strategy: Box::new(EfficientCompressionStrategy), // ä½¿ç”¨é«˜æ•ˆå‹ç¼©ç­–ç•¥
            kv_cache,
            config,
        }
    }

    /// åˆ›å»ºå¸¦è‡ªå®šä¹‰ç­–ç•¥çš„ç®¡ç†å™¨
    pub fn with_strategy(config: ContextConfig, strategy: Box<dyn CompressionStrategy>) -> Self {
        let kv_cache = KVCache::new(config.kv_cache.clone());
        Self {
            loop_detector: LoopDetector::new(8),
            strategy,
            kv_cache,
            config,
        }
    }

    /// æ„å»ºæ™ºèƒ½ä¸Šä¸‹æ–‡ - ä¸»è¦API
    pub async fn build_context(
        &self,
        repos: &RepositoryManager,
        conv_id: i64,
        up_to_msg_id: Option<i64>,
    ) -> AppResult<ContextResult> {
        info!("æ„å»ºæ™ºèƒ½ä¸Šä¸‹æ–‡: conv={}, up_to={:?}", conv_id, up_to_msg_id);

        // 1. è·å–åŸå§‹æ¶ˆæ¯
        let raw_msgs = self.fetch_messages(repos, conv_id, up_to_msg_id).await?;
        if raw_msgs.is_empty() {
            debug!("æ¶ˆæ¯åˆ—è¡¨ä¸ºç©º");
            return Ok(ContextResult {
                messages: Vec::new(),
                original_count: 0,
                token_count: 0,
                compressed: false,
            });
        }

        let token_count = self.estimate_tokens(&raw_msgs);
        let original_count = raw_msgs.len();

        // 2. æ™ºèƒ½å‹ç¼©åˆ¤æ–­é€»è¾‘
        let compression_decision = self.make_compression_decision(&raw_msgs, token_count);
        
        let processed_msgs = match compression_decision {
            CompressionDecision::NoCompression => {
                debug!("æ— éœ€å‹ç¼©ï¼Œæ‰§è¡Œå¾ªç¯æ£€æµ‹");
                self.loop_detector.remove_loops(raw_msgs)
            },
            CompressionDecision::LightCompression => {
                debug!("æ‰§è¡Œè½»é‡å‹ç¼©");
                self.apply_light_compression(&raw_msgs)?
            },
            CompressionDecision::HeavyCompression => {
                info!("æ‰§è¡Œæ·±åº¦å‹ç¼©: tokens={}/{}, æ¶ˆæ¯æ•°={}", 
                      token_count, self.config.max_tokens, original_count);
                let compressed = self.strategy.compress(&raw_msgs, &self.config)?;
                self.loop_detector.remove_loops(compressed)
            },
        };

        let final_token_count = self.estimate_tokens(&processed_msgs);
        
        debug!(
            "ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ: {} -> {} æ¡æ¶ˆæ¯, tokens: {} -> {}",
            original_count, processed_msgs.len(), token_count, final_token_count
        );

        Ok(ContextResult {
            messages: processed_msgs,
            original_count,
            token_count: final_token_count,
            compressed: !matches!(compression_decision, CompressionDecision::NoCompression),
        })
    }

    /// æ™ºèƒ½å‹ç¼©å†³ç­–
    fn make_compression_decision(&self, msgs: &[Message], token_count: usize) -> CompressionDecision {
        let token_ratio = token_count as f32 / self.config.max_tokens as f32;
        let msg_count = msgs.len();
        
        // è®¡ç®—å‹åŠ›æŒ‡æ ‡
        let token_pressure = token_ratio > self.config.compress_threshold;
        let message_pressure = msg_count > self.config.keep_recent + self.config.keep_important;
        let tool_message_ratio = msgs.iter().filter(|m| m.steps_json.is_some()).count() as f32 / msg_count as f32;

        match (token_pressure, message_pressure, tool_message_ratio > 0.6) {
            (false, false, _) => CompressionDecision::NoCompression,
            (false, true, false) => CompressionDecision::LightCompression,
            (true, _, _) | (_, true, true) => CompressionDecision::HeavyCompression,
        }
    }

    /// è½»é‡å‹ç¼© - ä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼Œç§»é™¤å†—ä½™
    fn apply_light_compression(&self, msgs: &[Message]) -> AppResult<Vec<Message>> {
        let mut result = Vec::new();
        let _scorer = AdvancedMessageScorer::new();

        // 1. ä¿ç•™æ‰€æœ‰ç³»ç»Ÿæ¶ˆæ¯
        result.extend(msgs.iter().filter(|m| m.role == "system").cloned());

        // 2. ä¿ç•™æ‰€æœ‰å·¥å…·æ‰§è¡Œæ¶ˆæ¯ï¼ˆå·¥å…·é“¾å®Œæ•´æ€§é‡è¦ï¼‰
        result.extend(msgs.iter().filter(|m| m.steps_json.is_some()).cloned());

        // 3. ä¿ç•™æœ€è¿‘çš„å¯¹è¯
        let recent_start = msgs.len().saturating_sub(self.config.keep_recent);
        for msg in &msgs[recent_start..] {
            if !result.iter().any(|m| m.id == msg.id) {
                result.push(msg.clone());
            }
        }

        // 4. ç§»é™¤ä½è´¨é‡é‡å¤æ¶ˆæ¯
        result.sort_by(|a, b| a.created_at.cmp(&b.created_at));
        result.dedup_by(|a, b| {
            if a.id == b.id {
                return true;
            }
            // å†…å®¹ç›¸ä¼¼åº¦å»é‡
            let similarity = self.content_similarity(&a.content, &b.content);
            similarity > 0.9 && (a.content.len() < b.content.len())
        });

        debug!("è½»é‡å‹ç¼©: {} -> {} æ¡æ¶ˆæ¯", msgs.len(), result.len());
        Ok(result)
    }

    /// è®¡ç®—å†…å®¹ç›¸ä¼¼åº¦
    fn content_similarity(&self, content1: &str, content2: &str) -> f64 {
        let words1: std::collections::HashSet<_> = content1.split_whitespace().collect();
        let words2: std::collections::HashSet<_> = content2.split_whitespace().collect();
        
        let intersection = words1.intersection(&words2).count();
        let union = words1.union(&words2).count();
        
        if union == 0 { 0.0 } else { intersection as f64 / union as f64 }
    }

    /// æ„å»ºå¸¦æ‘˜è¦çš„prompt - é›†æˆKV Cache
    pub async fn build_prompt(
        &self,
        repos: &RepositoryManager,
        conv_id: i64,
        current_msg: &str,
        up_to_msg_id: Option<i64>,
    ) -> AppResult<String> {
        // 1. è·å–å†å²æ¶ˆæ¯ç”¨äºç¼“å­˜é”®è®¡ç®—ï¼ˆæ’é™¤å½“å‰æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯ï¼‰
        let raw_msgs = self.fetch_messages(repos, conv_id, up_to_msg_id).await?;
        
        // æ’é™¤æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆå½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼‰ï¼Œåªå¯¹å†å²æ¶ˆæ¯åšç¼“å­˜
        let history_msgs = if raw_msgs.len() > 1 {
            &raw_msgs[..raw_msgs.len()-1]
        } else {
            &raw_msgs[..]
        };

        // 2. å°è¯•ä»KVç¼“å­˜è·å–
        if let Some(cached_prompt) = self.kv_cache.get(conv_id, history_msgs) {
            info!("KVç¼“å­˜å‘½ä¸­: conv={}", conv_id);

            // ç¼“å­˜å‘½ä¸­æ—¶ï¼Œåªéœ€è¦æ·»åŠ å½“å‰æ¶ˆæ¯
            return Ok(format!(
                "{}\n\nã€å½“å‰é—®é¢˜ã€‘\n{}",
                cached_prompt, current_msg
            ));
        }

        // 3. ç¼“å­˜æœªå‘½ä¸­ï¼Œæ„å»ºå®Œæ•´prompt
        info!("KVç¼“å­˜æœªå‘½ä¸­ï¼Œæ„å»ºæ–°prompt: conv={}", conv_id);

        let ctx = self.build_context(repos, conv_id, up_to_msg_id).await?;

        // è·å–ç”¨æˆ·å‰ç½®æç¤ºè¯
        let prefix = repos
            .ai_models()
            .get_user_prefix_prompt()
            .await?
            .unwrap_or_default();

        let mut parts = Vec::new();

        // æ·»åŠ å‰ç½®æç¤ºè¯ (ç¨³å®šå‰ç¼€)
        if !prefix.trim().is_empty() {
            parts.push(format!("ã€å‰ç½®æç¤ºã€‘\n{}\n", prefix));
        }

        // æ„å»ºå†å²å¯¹è¯ (å¯å˜éƒ¨åˆ†)
        if !ctx.messages.is_empty() {
            let history = ctx
                .messages
                .iter()
                .map(|m| self.format_message(m))
                .collect::<Vec<_>>()
                .join("\n");

            let compression_info = if ctx.compressed {
                format!("ï¼Œå·²æ™ºèƒ½å‹ç¼©è‡³{}æ¡", ctx.messages.len())
            } else {
                String::new()
            };

            parts.push(format!(
                "ã€å¯¹è¯å†å²ã€‘(å…±{}æ¡æ¶ˆæ¯{})\n{}\n",
                ctx.original_count, compression_info, history
            ));
        }

        // 4. ç¼“å­˜ç¨³å®šéƒ¨åˆ† (å‰ç¼€ + å†å²å¯¹è¯)
        let stable_content = parts.join("\n");
        self.kv_cache
            .put(conv_id, history_msgs, stable_content.clone());

        // 5. æ·»åŠ å½“å‰é—®é¢˜å¹¶è¿”å›
        parts.push(format!("ã€å½“å‰é—®é¢˜ã€‘\n{}", current_msg));
        Ok(parts.join("\n"))
    }

    // ============= ç§æœ‰æ–¹æ³• =============

    async fn fetch_messages(
        &self,
        repos: &RepositoryManager,
        conv_id: i64,
        _up_to_msg_id: Option<i64>,
    ) -> AppResult<Vec<Message>> {
        // TODO: å®ç°up_to_message_idé€»è¾‘
        repos
            .conversations()
            .get_messages(conv_id, None, None)
            .await
    }

    /// æ™ºèƒ½tokenä¼°ç®— - è€ƒè™‘ä¸åŒå†…å®¹ç±»å‹
    fn estimate_tokens(&self, msgs: &[Message]) -> usize {
        msgs.iter()
            .map(|msg| self.estimate_single_message_tokens(msg))
            .sum()
    }

    /// ä¼°ç®—å•æ¡æ¶ˆæ¯çš„tokenæ•°
    fn estimate_single_message_tokens(&self, msg: &Message) -> usize {
        let mut tokens = 0;

        // åŸºç¡€å†…å®¹tokenä¼°ç®—
        tokens += self.estimate_text_tokens(&msg.content);

        // è§’è‰²æ ‡è¯†token
        tokens += match msg.role.as_str() {
            "system" => 10,     // ç³»ç»Ÿæ¶ˆæ¯æœ‰é¢å¤–ç»“æ„åŒ–å¼€é”€
            "assistant" => 5,   // åŠ©æ‰‹å›å¤æœ‰å·¥å…·è°ƒç”¨å¯èƒ½
            "user" => 3,        // ç”¨æˆ·æ¶ˆæ¯ç›¸å¯¹ç®€å•
            _ => 2,
        };

        // å·¥å…·æ‰§è¡ŒJSONçš„tokenä¼°ç®—
        if let Some(ref steps_json) = msg.steps_json {
            tokens += self.estimate_json_tokens(steps_json);
        }

        // æ¶ˆæ¯å…ƒæ•°æ®å¼€é”€
        tokens += 8; // IDã€æ—¶é—´æˆ³ç­‰å…ƒæ•°æ®

        tokens
    }

    /// ä¼°ç®—æ–‡æœ¬å†…å®¹çš„tokenæ•°
    fn estimate_text_tokens(&self, text: &str) -> usize {
        if text.is_empty() {
            return 0;
        }

        let char_count = text.chars().count();
        let word_count = text.split_whitespace().count();
        
        // ä¸­è‹±æ–‡æ··åˆæ–‡æœ¬çš„tokenä¼°ç®—
        let chinese_chars = text.chars().filter(|c| c.is_ascii_punctuation() || (*c as u32) > 127).count();
        let english_chars = char_count - chinese_chars;

        // ä¸­æ–‡å­—ç¬¦çº¦1ä¸ªtokenï¼Œè‹±æ–‡å•è¯çº¦0.75ä¸ªtoken
        let estimated_tokens = (chinese_chars as f64 * 1.0) + (word_count as f64 * 0.75);

        // ä»£ç å—å’Œç‰¹æ®Šæ ¼å¼çš„tokenæˆæœ¬æ›´é«˜
        let code_blocks = text.matches("```").count() / 2;
        let json_objects = text.matches('{').count().min(text.matches('}').count());
        
        (estimated_tokens + code_blocks as f64 * 5.0 + json_objects as f64 * 2.0) as usize
    }

    /// ä¼°ç®—JSONå†…å®¹çš„tokenæ•°
    fn estimate_json_tokens(&self, json_str: &str) -> usize {
        // JSONç»“æ„åŒ–æ•°æ®çš„tokenæˆæœ¬é€šå¸¸æ¯”çº¯æ–‡æœ¬é«˜
        let base_tokens = self.estimate_text_tokens(json_str);
        
        // JSONç»“æ„å¼€é”€
        let object_count = json_str.matches('{').count();
        let array_count = json_str.matches('[').count();
        let string_count = json_str.matches('"').count() / 2;
        
        base_tokens + object_count * 2 + array_count + string_count
    }

    fn format_message(&self, msg: &Message) -> String {
        if msg.role == "assistant" && msg.steps_json.is_some() {
            let steps_json = msg.steps_json.as_ref().unwrap();
            info!("ğŸ” åŸå§‹steps_json: {}", steps_json);

            if let Ok(steps_value) = serde_json::from_str(steps_json) {
                let tool_summary = self.extract_tool_summary(&steps_value);

                // AbortErrorç‰¹æ®Šå¤„ç†: åªä¿ç•™å·¥å…·ä¿¡æ¯ï¼Œä¸æ˜¾ç¤ºä¸­æ–­æ–‡æœ¬
                if msg.content.contains("AbortError") {
                    return format!("assistant: {}", tool_summary);
                }

                // æ­£å¸¸å·¥å…·æ¶ˆæ¯: ç»“åˆå·¥å…·æ‘˜è¦å’Œæœ€ç»ˆå†…å®¹
                return format!("assistant: {}\n{}", tool_summary, msg.content.trim());
            }
        }

        // é»˜è®¤æ ¼å¼åŒ–
        format!("{}: {}", msg.role, msg.content)
    }

    fn extract_tool_summary(&self, steps: &serde_json::Value) -> String {
        if let Some(array) = steps.as_array() {
            let mut tool_calls = Vec::new();
            
            for step in array {
                if step.get("type").and_then(|t| t.as_str()) == Some("tool_use") {
                    if let Some(tool_exec) = step.get("toolExecution") {
                        let tool_name = tool_exec.get("name")
                            .and_then(|n| n.as_str())
                            .unwrap_or("unknown");
                        
                        // æ£€æŸ¥æ˜¯å¦æ‰§è¡Œå¤±è´¥
                        let is_error = tool_exec.get("result")
                            .and_then(|r| r.get("content"))
                            .and_then(|c| c.as_array())
                            .and_then(|arr| arr.first())
                            .and_then(|item| item.get("text"))
                            .and_then(|text| text.as_str())
                            .map(|text| text.contains("ToolError:"))
                            .unwrap_or(false);
                        
                        let tool_display = if is_error {
                            format!("{}(failed)", tool_name)
                        } else {
                            tool_name.to_string()
                        };
                        
                        tool_calls.push(tool_display);
                    }
                }
            }

            if !tool_calls.is_empty() {
                return format!("Tools: {}", tool_calls.join(" â†’ "));
            }
        }

        "Completed".to_string()
    }

    /// è·å–KVç¼“å­˜ç»Ÿè®¡
    pub fn cache_stats(&self) -> CacheStats {
        self.kv_cache.stats()
    }

    /// æ¸…ç†è¿‡æœŸç¼“å­˜
    pub fn cleanup_cache(&self) {
        self.kv_cache.cleanup_expired()
    }

    /// æ‰‹åŠ¨å¤±æ•ˆç¼“å­˜ (å½“å¯¹è¯è¢«ä¿®æ”¹æ—¶è°ƒç”¨)
    pub fn invalidate_cache(&self, conv_id: i64) {
        let mut cache = self.kv_cache.cache.lock().unwrap();
        cache.retain(|key, _| !key.contains(&format!("ctx_{}_", conv_id)));
        info!("æ‰‹åŠ¨å¤±æ•ˆç¼“å­˜: conv={}", conv_id);
    }
}

// ============= ç»“æœç±»å‹ =============

/// ä¸Šä¸‹æ–‡æ„å»ºç»“æœ
#[derive(Debug)]
pub struct ContextResult {
    pub messages: Vec<Message>,
    pub original_count: usize,
    pub token_count: usize,
    pub compressed: bool,
}

impl ContextResult {
    /// è½¬ä¸ºAIä¸Šä¸‹æ–‡æ ¼å¼
    pub fn to_ai_context(self) -> crate::ai::types::AIContext {
        crate::ai::types::AIContext {
            chat_history: Some(self.messages),
            ..Default::default()
        }
    }
}

// ============= å·¥å‚æ–¹æ³• =============

/// åˆ›å»ºé»˜è®¤ä¸Šä¸‹æ–‡ç®¡ç†å™¨
pub fn create_context_manager() -> ContextManager {
    ContextManager::new(ContextConfig::default())
}

/// åˆ›å»ºè‡ªå®šä¹‰é…ç½®çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
pub fn create_context_manager_with_config(config: ContextConfig) -> ContextManager {
    ContextManager::new(config)
}
