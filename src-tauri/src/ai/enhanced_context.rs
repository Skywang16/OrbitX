use crate::ai::types::Message;
use crate::storage::repositories::RepositoryManager;
use crate::utils::error::AppResult;
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};
use std::sync::{Arc, Mutex};
use tracing::{debug, info};
use tiktoken_rs::{cl100k_base, CoreBPE};

// ============= é…ç½®å±‚ =============

/// ä¸Šä¸‹æ–‡ç®¡ç†é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContextConfig {
    /// æœ€å¤§tokenæ•°é‡
    pub max_tokens: usize,
    /// å‹ç¼©è§¦å‘é˜ˆå€¼(0.0-1.0)
    pub compress_threshold: f32,
    /// ä¿ç•™æœ€è¿‘æ¶ˆæ¯æ•°
    pub keep_recent: usize,
    /// ä¿ç•™é‡è¦æ¶ˆæ¯æ•°
    pub keep_important: usize,
    /// æœ€å°å‹ç¼©æ‰¹æ¬¡å¤§å°
    pub min_compress_batch: usize,
    /// æ‘˜è¦çª—å£å¤§å°
    pub summary_window_size: usize,
    /// é‡è¦æ€§é˜ˆå€¼
    pub importance_threshold: f32,
    /// KVç¼“å­˜é…ç½®
    pub kv_cache: KVCacheConfig,
}

/// KVç¼“å­˜é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct KVCacheConfig {
    /// æ˜¯å¦å¯ç”¨KVç¼“å­˜
    pub enabled: bool,
    /// ç¼“å­˜TTLï¼ˆç§’ï¼‰
    pub ttl_seconds: u64,
    /// æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
    pub max_entries: usize,
    /// ç¨³å®šå‰ç¼€æœ€å¤§é•¿åº¦
    pub stable_prefix_max_tokens: usize,
}

impl Default for KVCacheConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            ttl_seconds: 3600, // 1å°æ—¶
            max_entries: 100,
            stable_prefix_max_tokens: 1000,
        }
    }
}

impl Default for ContextConfig {
    fn default() -> Self {
        Self {
            max_tokens: 100000,
            compress_threshold: 0.92,  // 92%è§¦å‘é˜ˆå€¼ (Claude Codeæ ‡å‡†)
            keep_recent: 12,           // ä¿ç•™æœ€è¿‘12æ¡æ¶ˆæ¯
            keep_important: 8,         // é‡è¦æ¶ˆæ¯æ•°é‡ä¼˜åŒ–
            min_compress_batch: 3,     // å‡å°‘æœ€å°æ‰¹æ¬¡
            summary_window_size: 8,    // ä¼˜åŒ–çª—å£å¤§å°
            importance_threshold: 0.7, // æé«˜é‡è¦æ€§é˜ˆå€¼
            kv_cache: KVCacheConfig::default(),
        }
    }
}

// ============= KVç¼“å­˜å±‚ =============

/// KVç¼“å­˜é¡¹
#[derive(Debug, Clone)]
pub struct CacheEntry {
    /// ç¼“å­˜çš„ä¸Šä¸‹æ–‡å†…å®¹
    pub content: String,
    /// æ¶ˆæ¯åˆ—è¡¨çš„å“ˆå¸Œå€¼
    pub messages_hash: u64,
    /// åˆ›å»ºæ—¶é—´
    pub created_at: DateTime<Utc>,
    /// æœ€åè®¿é—®æ—¶é—´
    pub last_accessed: DateTime<Utc>,
    /// å‘½ä¸­æ¬¡æ•°
    pub hit_count: u64,
    /// ç¨³å®šå‰ç¼€é•¿åº¦
    pub stable_prefix_len: usize,
    /// è¯­ä¹‰å“ˆå¸Œï¼ˆåŸºäºæ¶ˆæ¯è¯­ä¹‰è€Œéç®€å•æ–‡æœ¬ï¼‰
    pub semantic_hash: u64,
    /// è®¿é—®é¢‘ç‡æƒé‡
    pub access_weight: f64,
}

/// KVç¼“å­˜ç®¡ç†å™¨ - åŸºäºManusåŸç†
pub struct KVCache {
    /// ç¼“å­˜å­˜å‚¨
    cache: Arc<Mutex<HashMap<String, CacheEntry>>>,
    /// é…ç½®
    config: KVCacheConfig,
    /// åˆ†è¯å™¨ï¼ˆå¯é€‰ï¼‰
    tokenizer: Option<Arc<CoreBPE>>,
}

impl KVCache {
    pub fn new(config: KVCacheConfig, tokenizer: Option<Arc<CoreBPE>>) -> Self {
        Self {
            cache: Arc::new(Mutex::new(HashMap::new())),
            config,
            tokenizer,
        }
    }

    /// ç”Ÿæˆç¼“å­˜é”® - åŸºäºå¯¹è¯IDå’Œå‰ç¼€å“ˆå¸Œ
    fn generate_cache_key(&self, conv_id: i64, prefix_hash: u64) -> String {
        format!("ctx_{}_{}", conv_id, prefix_hash)
    }

    /// è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„å“ˆå¸Œå€¼ï¼ˆç»“æ„åŒ–å“ˆå¸Œï¼‰
    fn hash_messages(&self, msgs: &[Message]) -> u64 {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        for msg in msgs {
            msg.id.hash(&mut hasher);
            msg.role.hash(&mut hasher);
            // å¯¹å†…å®¹è¿›è¡Œè§„èŒƒåŒ–å¤„ç†ï¼Œå¿½ç•¥ç©ºç™½å­—ç¬¦å·®å¼‚
            msg.content.trim().hash(&mut hasher);
            // å“ˆå¸Œå·¥å…·è°ƒç”¨ä¿¡æ¯
            if let Some(ref steps) = msg.steps_json {
                steps.hash(&mut hasher);
            }
            // çº³å…¥çŠ¶æ€ï¼ˆç”¨äºæ»šåŠ¨æ‘˜è¦ç‰ˆæœ¬ï¼Œç¡®ä¿ç¼“å­˜å¤±æ•ˆï¼‰
            if let Some(ref st) = msg.status {
                st.hash(&mut hasher);
            }
        }
        hasher.finish()
    }

    /// æ™ºèƒ½æå–ç¨³å®šå‰ç¼€ - è€ƒè™‘è¯­ä¹‰è¾¹ç•Œ
    pub fn extract_stable_prefix(&self, msgs: &[Message]) -> Vec<Message> {
        if msgs.is_empty() {
            return Vec::new();
        }

        let mut stable_msgs = Vec::new();
        let mut token_count = 0;
        let mut last_system_index = None;

        // é¦–å…ˆæ‰¾åˆ°æœ€åä¸€ä¸ªç³»ç»Ÿæ¶ˆæ¯ä½ç½®ä½œä¸ºæ½œåœ¨è¾¹ç•Œ
        for (i, msg) in msgs.iter().enumerate() {
            if msg.role == "system" {
                last_system_index = Some(i);
            }
        }

        // ä¼˜å…ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæ—©æœŸå¯¹è¯å»ºç«‹ä¸Šä¸‹æ–‡
        for (i, msg) in msgs.iter().enumerate() {
            let msg_tokens = self.estimate_message_tokens(msg);

            // å¦‚æœè¶…å‡ºtokené™åˆ¶ï¼Œæ£€æŸ¥æ˜¯å¦åœ¨è¯­ä¹‰è¾¹ç•Œ
            if token_count + msg_tokens > self.config.stable_prefix_max_tokens {
                // å¦‚æœå½“å‰ä½ç½®æ¥è¿‘ç³»ç»Ÿæ¶ˆæ¯è¾¹ç•Œï¼Œç»§ç»­åˆ°ç³»ç»Ÿæ¶ˆæ¯
                if let Some(sys_idx) = last_system_index {
                    if i <= sys_idx + 2 && token_count < self.config.stable_prefix_max_tokens * 2 {
                        // å…è®¸é€‚åº¦è¶…å‡ºä»¥ä¿æŒè¯­ä¹‰å®Œæ•´æ€§
                    } else {
                        break;
                    }
                } else {
                    break;
                }
            }

            stable_msgs.push(msg.clone());
            token_count += msg_tokens;

            // å¦‚æœå·²ç»åŒ…å«äº†ç³»ç»Ÿæ¶ˆæ¯åŠå…¶åç»­2-3æ¡æ¶ˆæ¯ï¼Œè€ƒè™‘åœæ­¢
            if let Some(sys_idx) = last_system_index {
                if i > sys_idx + 3 && token_count > self.config.stable_prefix_max_tokens / 2 {
                    break;
                }
            }
        }

        debug!(
            "æå–ç¨³å®šå‰ç¼€: {} -> {} æ¡æ¶ˆæ¯, {} tokens",
            msgs.len(),
            stable_msgs.len(),
            token_count
        );

        stable_msgs
    }

    /// æ›´å‡†ç¡®çš„tokenä¼°ç®—
    fn estimate_message_tokens(&self, msg: &Message) -> usize {
        // ä½¿ç”¨çœŸå®åˆ†è¯å™¨ï¼›è‹¥ä¸å¯ç”¨åˆ™å›é€€åˆ°ç®€å•ä¼°ç®—
        if let Some(tok) = &self.tokenizer {
            let mut tokens = tok.encode_ordinary(&msg.content).len();
            if let Some(ref steps) = msg.steps_json {
                tokens += tok.encode_ordinary(steps).len();
            }
            // è§’è‰²ä¸ç»“æ„é¢å¤–å¼€é”€
            tokens += match msg.role.as_str() {
                "system" => 6,
                "assistant" => 4,
                "user" => 3,
                _ => 2,
            };
            return tokens;
        }

        // fallback
        let content_tokens = msg.content.len() / 3;
        let steps_tokens = msg.steps_json.as_ref().map(|s| s.len() / 4).unwrap_or(0);
        content_tokens + steps_tokens
    }

    /// é«˜æ•ˆç¼“å­˜è·å– - ç²¾ç¡®åŒ¹é…ä¼˜å…ˆ
    pub fn get(&self, conv_id: i64, msgs: &[Message]) -> Option<String> {
        if !self.config.enabled || msgs.is_empty() {
            return None;
        }

        let stable_prefix = self.extract_stable_prefix(msgs);
        let prefix_hash = self.hash_messages(&stable_prefix);
        let cache_key = self.generate_cache_key(conv_id, prefix_hash);

        let mut cache = self.cache.lock().ok()?;

        if let Some(entry) = cache.get_mut(&cache_key) {
            if self.is_entry_valid(entry) {
                self.update_entry_access(entry);
                debug!("ç¼“å­˜å‘½ä¸­: {} (hits: {})", cache_key, entry.hit_count);
                return Some(entry.content.clone());
            } else {
                cache.remove(&cache_key);
                debug!("æ¸…ç†è¿‡æœŸç¼“å­˜: {}", cache_key);
            }
        }

        debug!("ç¼“å­˜æœªå‘½ä¸­: {}", cache_key);
        None
    }

    /// æ£€æŸ¥ç¼“å­˜æ¡ç›®æ˜¯å¦æœ‰æ•ˆï¼ˆTTLå’Œå…¶ä»–æ¡ä»¶ï¼‰
    fn is_entry_valid(&self, entry: &CacheEntry) -> bool {
        let now = Utc::now();
        let elapsed = now.signed_duration_since(entry.created_at).num_seconds();
        elapsed >= 0 && (elapsed as u64) <= self.config.ttl_seconds
    }

    /// æ›´æ–°ç¼“å­˜æ¡ç›®çš„è®¿é—®ä¿¡æ¯
    fn update_entry_access(&self, entry: &mut CacheEntry) {
        let now = Utc::now();
        entry.hit_count += 1;
        entry.last_accessed = now;

        // åŠ¨æ€è°ƒæ•´è®¿é—®æƒé‡ï¼šæœ€è¿‘è®¿é—® + é¢‘ç‡
        let recency_weight = 1.0
            / (1.0 + (now.signed_duration_since(entry.last_accessed).num_minutes() as f64 / 60.0));
        let frequency_weight = (entry.hit_count as f64).ln() / 10.0;
        entry.access_weight = recency_weight + frequency_weight;
    }

    /// é«˜æ•ˆç¼“å­˜å­˜å‚¨ - ç®€åŒ–çš„LRUæœºåˆ¶
    pub fn put(&self, conv_id: i64, msgs: &[Message], content: String) {
        if !self.config.enabled || msgs.is_empty() {
            return;
        }

        let stable_prefix = self.extract_stable_prefix(msgs);
        let prefix_hash = self.hash_messages(&stable_prefix);
        let cache_key = self.generate_cache_key(conv_id, prefix_hash);
        let messages_hash = self.hash_messages(msgs);

        let mut cache = self.cache.lock().unwrap();

        // ç®€åŒ–çš„ç¼“å­˜ç©ºé—´ç®¡ç†
        if cache.len() >= self.config.max_entries {
            let oldest_key = cache
                .iter()
                .min_by_key(|(_, entry)| entry.last_accessed)
                .map(|(k, _)| k.clone());
            if let Some(key) = oldest_key {
                cache.remove(&key);
                debug!("LRUæ¸…ç†ç¼“å­˜: {}", key);
            }
        }

        let now = Utc::now();
        let entry = CacheEntry {
            content,
            messages_hash,
            created_at: now,
            last_accessed: now,
            hit_count: 0,
            stable_prefix_len: stable_prefix.len(),
            semantic_hash: 0, // ç®€åŒ–ï¼Œä¸ä½¿ç”¨è¯­ä¹‰å“ˆå¸Œ
            access_weight: 1.0,
        };

        cache.insert(cache_key.clone(), entry);
        debug!("ç¼“å­˜å­˜å‚¨: {}", cache_key);
    }

    /// è·å–ç¼“å­˜ç»Ÿè®¡
    pub fn stats(&self) -> CacheStats {
        let cache = self.cache.lock().unwrap();
        let total_hits: u64 = cache.values().map(|e| e.hit_count).sum();
        let total_entries = cache.len();

        CacheStats {
            total_entries,
            total_hits,
            hit_rate: if total_entries > 0 {
                total_hits as f64 / (total_entries as f64 + total_hits as f64)
            } else {
                0.0
            },
        }
    }

    /// æ¸…ç†è¿‡æœŸç¼“å­˜
    pub fn cleanup_expired(&self) {
        let mut cache = self.cache.lock().unwrap();
        let now = Utc::now();

        cache.retain(|key, entry| {
            let elapsed = now.signed_duration_since(entry.created_at).num_seconds();
            if elapsed as u64 > self.config.ttl_seconds {
                debug!("æ¸…ç†è¿‡æœŸç¼“å­˜: {}", key);
                false
            } else {
                true
            }
        });
    }
}

/// ç¼“å­˜ç»Ÿè®¡
#[derive(Debug, Clone)]
pub struct CacheStats {
    pub total_entries: usize,
    pub total_hits: u64,
    pub hit_rate: f64,
}

// ============= ç­–ç•¥å±‚ =============

/// å‹ç¼©ç­–ç•¥ç‰¹å¾
pub trait CompressionStrategy: Send + Sync {
    fn compress(&self, msgs: &[Message], config: &ContextConfig) -> AppResult<Vec<Message>>;
}

/// é«˜æ•ˆå‹ç¼©ç­–ç•¥ - åŸºäºClaude Codeçš„30%ä¿ç•™ç‡å®ç°
pub struct EfficientCompressionStrategy;

/// æ¶ˆæ¯é‡è¦æ€§è¯„ä¼°
#[derive(Debug, Clone)]
struct MessageImportance {
    pub index: usize,
    pub message: Message,
    pub importance_score: f64,
    pub is_system: bool,
}

impl CompressionStrategy for EfficientCompressionStrategy {
    fn compress(&self, msgs: &[Message], config: &ContextConfig) -> AppResult<Vec<Message>> {
        if msgs.len() < config.min_compress_batch {
            debug!("æ¶ˆæ¯æ•°é‡ä¸è¶³ï¼Œè·³è¿‡å‹ç¼©: {}", msgs.len());
            return Ok(msgs.to_vec());
        }

        debug!("å¼€å§‹é«˜æ•ˆå‹ç¼©: {} æ¡æ¶ˆæ¯", msgs.len());

        // è®¡ç®—30%ä¿ç•™ç›®æ ‡æ•°é‡ (Claude Codeæ ‡å‡†)
        let target_count =
            (msgs.len() as f64 * 0.30).max(config.min_compress_batch as f64) as usize;

        // 1. åˆ†ææ¶ˆæ¯é‡è¦æ€§
        let importance_analysis = self.analyze_message_importance(msgs);

        // 2. åº”ç”¨ä¿ç•™ç­–ç•¥
        let preserved_messages =
            self.apply_retention_strategy(importance_analysis, target_count, config)?;

        // 3. æœ€ç»ˆæ’åºå’Œå»é‡
        self.finalize_result(preserved_messages, msgs.len())
    }
}

impl EfficientCompressionStrategy {
    /// å¿«é€Ÿé‡è¦æ€§åˆ†æ
    fn analyze_message_importance(&self, msgs: &[Message]) -> Vec<MessageImportance> {
        let scorer = AdvancedMessageScorer::new();

        msgs.iter()
            .enumerate()
            .map(|(index, msg)| {
                let importance_score = scorer.compute_comprehensive_score(msg, index, msgs.len());

                MessageImportance {
                    index,
                    message: msg.clone(),
                    importance_score,
                    is_system: msg.role == "system",
                }
            })
            .collect()
    }

    /// é«˜æ•ˆä¿ç•™ç­–ç•¥ - åŸºäº30%ç›®æ ‡
    fn apply_retention_strategy(
        &self,
        mut analysis: Vec<MessageImportance>,
        target_count: usize,
        config: &ContextConfig,
    ) -> AppResult<Vec<MessageImportance>> {
        let mut result = Vec::new();

        // 1. å¼ºåˆ¶ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
        for item in &analysis {
            if item.is_system {
                result.push(item.clone());
            }
        }

        // 2. ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯ï¼ˆä¿è¯è¿ç»­æ€§ï¼‰
        let recent_start = analysis.len().saturating_sub(config.keep_recent);
        for item in &analysis[recent_start..] {
            if !item.is_system && !result.iter().any(|r| r.index == item.index) {
                result.push(item.clone());
            }
        }

        // 3. å¦‚æœè¿˜éœ€è¦æ›´å¤šæ¶ˆæ¯ï¼ŒæŒ‰é‡è¦æ€§é€‰æ‹©
        if result.len() < target_count {
            analysis.sort_by(|a, b| {
                b.importance_score
                    .partial_cmp(&a.importance_score)
                    .unwrap_or(std::cmp::Ordering::Equal)
            });

            let needed = target_count - result.len();
            for item in analysis.iter().take(needed * 2) {
                if result.len() >= target_count {
                    break;
                }
                if !result.iter().any(|r| r.index == item.index) {
                    result.push(item.clone());
                }
            }
        }

        // æ’åºå’Œå»é‡
        result.sort_by_key(|m| m.index);
        result.dedup_by_key(|m| m.message.id);

        debug!(
            "ä¿ç•™ç­–ç•¥ç»“æœ: {} -> {} æ¡æ¶ˆæ¯",
            analysis.len(),
            result.len()
        );
        Ok(result)
    }

    /// æœ€ç»ˆç»“æœå¤„ç†
    fn finalize_result(
        &self,
        mut messages: Vec<MessageImportance>,
        original_count: usize,
    ) -> AppResult<Vec<Message>> {
        // æŒ‰æ—¶é—´é¡ºåºæ’åº
        messages.sort_by_key(|m| m.index);

        let result: Vec<Message> = messages.into_iter().map(|m| m.message).collect();
        let compression_rate = (1.0 - result.len() as f64 / original_count as f64) * 100.0;

        debug!(
            "é«˜æ•ˆå‹ç¼©å®Œæˆ: {} -> {} æ¡æ¶ˆæ¯ (å‹ç¼©ç‡: {:.1}%)",
            original_count,
            result.len(),
            compression_rate
        );

        Ok(result)
    }
}

/// å¾ªç¯æ£€æµ‹ç­–ç•¥
pub struct LoopDetector {
    window_size: usize,
}

impl LoopDetector {
    pub fn new(window_size: usize) -> Self {
        Self { window_size }
    }

    pub fn remove_loops(&self, msgs: Vec<Message>) -> Vec<Message> {
        let mut result = Vec::new();
        let mut seen_hashes = HashMap::new();

        for (idx, msg) in msgs.into_iter().enumerate() {
            let hash = self.content_hash(&msg.content);

            if let Some(&last_idx) = seen_hashes.get(&hash) {
                if idx - last_idx <= self.window_size {
                    debug!("è·³è¿‡å¾ªç¯æ¶ˆæ¯: {:?}", msg.id);
                    continue;
                }
            }

            seen_hashes.insert(hash, idx);
            result.push(msg);
        }

        result
    }

    fn content_hash(&self, content: &str) -> u64 {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        content.hash(&mut hasher);
        hasher.finish()
    }
}

// ============= è¯„åˆ†å±‚ =============

/// é«˜çº§æ¶ˆæ¯è¯„åˆ†å™¨ - å¤šç»´åº¦è¯„åˆ†
pub struct AdvancedMessageScorer {
    keyword_weights: HashMap<&'static str, f32>,
    semantic_weights: HashMap<&'static str, f32>,
}

/// ç®€å•æ¶ˆæ¯è¯„åˆ†å™¨ï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼‰
pub struct MessageScorer {
    keyword_weights: HashMap<&'static str, f32>,
}

impl AdvancedMessageScorer {
    pub fn new() -> Self {
        let mut keyword_weights = HashMap::new();
        keyword_weights.insert("error", 3.0);
        keyword_weights.insert("warning", 2.5);
        keyword_weights.insert("failed", 2.8);
        keyword_weights.insert("success", 2.0);
        keyword_weights.insert("config", 1.8);
        keyword_weights.insert("install", 1.6);
        keyword_weights.insert("debug", 1.4);
        keyword_weights.insert("important", 2.2);
        keyword_weights.insert("critical", 3.2);

        let mut semantic_weights = HashMap::new();
        semantic_weights.insert("question", 1.5);
        semantic_weights.insert("solution", 2.0);
        semantic_weights.insert("problem", 1.8);
        semantic_weights.insert("implement", 1.6);
        semantic_weights.insert("fix", 2.2);
        semantic_weights.insert("optimize", 1.7);

        Self {
            keyword_weights,
            semantic_weights,
        }
    }

    /// è®¡ç®—ç»¼åˆé‡è¦æ€§è¯„åˆ†
    pub fn compute_comprehensive_score(
        &self,
        msg: &Message,
        index: usize,
        total_msgs: usize,
    ) -> f64 {
        let mut score = 0.0;

        // 1. åŸºç¡€è§’è‰²æƒé‡
        score += match msg.role.as_str() {
            "system" => 4.0,
            "assistant" => 1.8,
            "user" => 1.2,
            _ => 0.8,
        };

        // 2. å·¥å…·æ‰§è¡Œé«˜æƒé‡ï¼ˆç¡®ä¿ä¿ç•™é‡è¦æ‰§è¡Œç»“æœï¼‰
        if msg.steps_json.is_some() {
            score += self.evaluate_tool_execution_importance(msg);
        }

        // 3. å†…å®¹è¯­ä¹‰è¯„åˆ†
        score += self.evaluate_content_semantics(&msg.content);

        // 4. ä½ç½®æƒé‡ï¼ˆæœ€è¿‘å’Œæœ€æ—©çš„æ¶ˆæ¯æ›´é‡è¦ï¼‰
        let position_weight = self.compute_position_weight(index, total_msgs);
        score *= position_weight;

        // 5. å†…å®¹é•¿åº¦è¯„åˆ†ï¼ˆé€‚ä¸­é•¿åº¦æœ€ä¼˜ï¼‰
        score += self.evaluate_content_length(&msg.content);

        // 6. æ—¶é—´è¡°å‡ï¼ˆè¾ƒæ–°çš„æ¶ˆæ¯æƒé‡æ›´é«˜ï¼‰
        score *= self.compute_time_decay(msg);

        // 7. å¯¹è¯è¿ç»­æ€§è¯„åˆ†ï¼ˆè€ƒè™‘ä¸Šä¸‹æ–‡å…³è”ï¼‰
        score += self.evaluate_conversational_continuity(msg);

        score.max(0.0).min(10.0)
    }

    /// è¯„ä¼°å·¥å…·æ‰§è¡Œé‡è¦æ€§
    fn evaluate_tool_execution_importance(&self, msg: &Message) -> f64 {
        let base_score = 4.0; // å·¥å…·æ‰§è¡ŒåŸºç¡€é«˜åˆ†

        if let Some(ref steps_json) = msg.steps_json {
            // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if steps_json.contains("ToolError") || steps_json.contains("failed") {
                return base_score + 2.0; // é”™è¯¯ä¿¡æ¯å¾ˆé‡è¦
            }

            // æ£€æŸ¥å·¥å…·ç±»å‹é‡è¦æ€§
            if steps_json.contains("Read")
                || steps_json.contains("Write")
                || steps_json.contains("Edit")
            {
                return base_score + 1.5; // æ–‡ä»¶æ“ä½œé‡è¦
            }

            if steps_json.contains("Bash") || steps_json.contains("Execute") {
                return base_score + 1.0; // å‘½ä»¤æ‰§è¡Œé‡è¦
            }
        }

        base_score
    }

    /// è¯„ä¼°å†…å®¹è¯­ä¹‰
    fn evaluate_content_semantics(&self, content: &str) -> f64 {
        let mut score = 0.0f64;
        let content_lower = content.to_lowercase();

        // å…³é”®è¯æƒé‡
        for (&keyword, &weight) in &self.keyword_weights {
            if content_lower.contains(keyword) {
                score += weight as f64;
            }
        }

        // è¯­ä¹‰æ¨¡å¼æƒé‡
        for (&pattern, &weight) in &self.semantic_weights {
            if content_lower.contains(pattern) {
                score += weight as f64;
            }
        }

        // é—®å·è¡¨ç¤ºé—®é¢˜ï¼Œé‡è¦æ€§è¾ƒé«˜
        let question_count = content.matches('?').count() as f64;
        score += question_count * 0.5;

        // ä»£ç å—è¡¨ç¤ºæŠ€æœ¯å†…å®¹ï¼Œé€‚åº¦åŠ åˆ†
        let code_block_count = content.matches("```").count() as f64 / 2.0;
        score += code_block_count * 0.8;

        score
    }

    /// è®¡ç®—ä½ç½®æƒé‡
    fn compute_position_weight(&self, index: usize, total_msgs: usize) -> f64 {
        if total_msgs <= 1 {
            return 1.0;
        }

        let relative_position = index as f64 / (total_msgs - 1) as f64;

        // æœ€è¿‘çš„æ¶ˆæ¯æƒé‡æœ€é«˜ï¼Œæœ€æ—©çš„æ¶ˆæ¯ä¹Ÿæœ‰ä¸€å®šæƒé‡
        if relative_position > 0.8 {
            1.4 // æœ€è¿‘20%çš„æ¶ˆæ¯
        } else if relative_position < 0.2 {
            1.2 // æœ€æ—©20%çš„æ¶ˆæ¯
        } else {
            1.0 // ä¸­é—´æ¶ˆæ¯æ­£å¸¸æƒé‡
        }
    }

    /// è¯„ä¼°å†…å®¹é•¿åº¦
    fn evaluate_content_length(&self, content: &str) -> f64 {
        match content.len() {
            0..=20 => 0.3,    // å¤ªçŸ­ï¼Œä¿¡æ¯é‡å°‘
            21..=100 => 1.2,  // é€‚ä¸­ï¼Œä¿¡æ¯å¯†åº¦é«˜
            101..=300 => 1.5, // è¾ƒé•¿ï¼Œä¿¡æ¯ä¸°å¯Œ
            301..=800 => 1.0, // å¾ˆé•¿ï¼Œå¯èƒ½æœ‰å†—ä½™
            _ => 0.6,         // è¿‡é•¿ï¼Œå¯èƒ½ä¿¡æ¯å†—ä½™
        }
    }

    /// è®¡ç®—æ—¶é—´è¡°å‡
    fn compute_time_decay(&self, msg: &Message) -> f64 {
        let created_at = chrono::DateTime::parse_from_rfc3339(&msg.created_at)
            .map(|dt| dt.with_timezone(&chrono::Utc))
            .unwrap_or_else(|_| chrono::Utc::now());

        let hours_ago = chrono::Utc::now()
            .signed_duration_since(created_at)
            .num_hours() as f64;

        // 48å°æ—¶åŠè¡°æœŸï¼Œä½†æœ€ä½ä¿æŒ30%æƒé‡
        let decay_factor = (-hours_ago / 48.0).exp();
        decay_factor.max(0.3)
    }

    /// è¯„ä¼°å¯¹è¯è¿ç»­æ€§
    fn evaluate_conversational_continuity(&self, msg: &Message) -> f64 {
        let mut score = 0.0;

        // å›å¤æŒ‡ç¤ºè¯åŠ åˆ†
        let content_lower = msg.content.to_lowercase();
        if content_lower.contains("thanks") || content_lower.contains("thank you") {
            score += 0.5;
        }

        if content_lower.contains("please") || content_lower.contains("help") {
            score += 0.8;
        }

        // ç¡®è®¤æˆ–å¦å®šè¯æ±‡
        if content_lower.contains("yes")
            || content_lower.contains("no")
            || content_lower.contains("ok")
            || content_lower.contains("sure")
        {
            score += 0.3;
        }

        score
    }
}

impl MessageScorer {
    pub fn new() -> Self {
        let mut weights = HashMap::new();
        weights.insert("error", 2.0);
        weights.insert("warning", 1.5);
        weights.insert("config", 1.3);
        weights.insert("install", 1.2);
        weights.insert("debug", 1.1);

        Self {
            keyword_weights: weights,
        }
    }

    pub fn score(&self, msg: &Message) -> f32 {
        let mut score = 0.0;

        // åŸºç¡€åˆ†ï¼šè§’è‰²æƒé‡
        score += match msg.role.as_str() {
            "system" => 3.0,
            "assistant" => 1.5,
            "user" => 1.0,
            _ => 0.5,
        };

        // å·¥å…·è°ƒç”¨åŠ åˆ†ï¼ˆå¤§å¹…æé«˜åˆ†æ•°ï¼Œç¡®ä¿é‡è¦å·¥å…·ç»“æœä¸è¢«ä¸¢å¤±ï¼‰
        if msg.steps_json.is_some() {
            score += 5.0; // ä»2.0æé«˜åˆ°5.0ï¼Œç¡®ä¿å·¥å…·æ‰§è¡Œæ¶ˆæ¯ä¼˜å…ˆä¿ç•™
        }

        // é•¿åº¦åˆ† (é€‚ä¸­é•¿åº¦å¾—åˆ†é«˜)
        let len_score = match msg.content.len() {
            0..=50 => 0.5,
            51..=200 => 1.5,
            201..=500 => 2.0,
            501..=1000 => 1.0,
            _ => 0.5,
        };
        score += len_score;

        // å…³é”®è¯åˆ†
        let content_lower = msg.content.to_lowercase();
        for (&keyword, &weight) in &self.keyword_weights {
            if content_lower.contains(keyword) {
                score += weight;
            }
        }

        // æ—¶é—´è¡°å‡ (24å°æ—¶åŠè¡°æœŸ)
        let created_at = chrono::DateTime::parse_from_rfc3339(&msg.created_at)
            .map(|dt| dt.with_timezone(&chrono::Utc))
            .unwrap_or_else(|_| chrono::Utc::now());
        let hours = chrono::Utc::now()
            .signed_duration_since(created_at)
            .num_hours() as f32;
        score *= (-hours / 24.0).exp();

        score.max(0.0).min(10.0)
    }
}

// ============= ç®¡ç†å±‚ =============

/// å‹ç¼©å†³ç­–ç±»å‹
#[derive(Debug, Clone, PartialEq)]
enum CompressionDecision {
    /// æ— éœ€å‹ç¼©
    NoCompression,
    /// è½»é‡å‹ç¼©ï¼ˆå»é™¤å†—ä½™ï¼Œä¿ç•™æ ¸å¿ƒï¼‰
    LightCompression,
    /// æ·±åº¦å‹ç¼©ï¼ˆä½¿ç”¨æ™ºèƒ½ç­–ç•¥å¤§å¹…å‹ç¼©ï¼‰
    HeavyCompression,
}

/// æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - ä¸»è¦å…¥å£
pub struct ContextManager {
    config: ContextConfig,
    strategy: Box<dyn CompressionStrategy>,
    loop_detector: LoopDetector,
    kv_cache: KVCache,
    /// å®é™…åˆ†è¯å™¨
    tokenizer: Arc<CoreBPE>,
}

impl ContextManager {
    pub fn new(config: ContextConfig) -> Self {
        let tokenizer = Arc::new(cl100k_base().expect("failed to init cl100k_base tokenizer"));
        let kv_cache = KVCache::new(config.kv_cache.clone(), Some(tokenizer.clone()));
        Self {
            loop_detector: LoopDetector::new(6), // ä¼˜åŒ–å¾ªç¯æ£€æµ‹çª—å£
            strategy: Box::new(EfficientCompressionStrategy), // ä½¿ç”¨é«˜æ•ˆå‹ç¼©ç­–ç•¥
            kv_cache,
            tokenizer,
            config,
        }
    }

    /// åˆ›å»ºå¸¦è‡ªå®šä¹‰ç­–ç•¥çš„ç®¡ç†å™¨
    pub fn with_strategy(config: ContextConfig, strategy: Box<dyn CompressionStrategy>) -> Self {
        let tokenizer = Arc::new(cl100k_base().expect("failed to init cl100k_base tokenizer"));
        let kv_cache = KVCache::new(config.kv_cache.clone(), Some(tokenizer.clone()));
        Self {
            loop_detector: LoopDetector::new(8),
            strategy,
            kv_cache,
            tokenizer,
            config,
        }
    }

    /// æ„å»ºæ™ºèƒ½ä¸Šä¸‹æ–‡ - ä¸»è¦API
    pub async fn build_context(
        &self,
        repos: &RepositoryManager,
        conv_id: i64,
        up_to_msg_id: Option<i64>,
    ) -> AppResult<ContextResult> {
        info!("æ„å»ºæ™ºèƒ½ä¸Šä¸‹æ–‡: conv={}, up_to={:?}", conv_id, up_to_msg_id);

        // 1. è·å–åŸå§‹æ¶ˆæ¯
        let mut raw_msgs = self.fetch_messages(repos, conv_id, up_to_msg_id).await?;
        if raw_msgs.is_empty() {
            debug!("æ¶ˆæ¯åˆ—è¡¨ä¸ºç©º");
            return Ok(ContextResult {
                messages: Vec::new(),
                original_count: 0,
                token_count: 0,
                compressed: false,
            });
        }

        let mut token_count = self.estimate_tokens(&raw_msgs);
        let original_count = raw_msgs.len();

        // å¦‚æœè¶…è¿‡ç¡¬ä¸Šé™ï¼Œç”Ÿæˆå¹¶æŒä¹…åŒ–æ»šåŠ¨æ‘˜è¦ï¼Œç„¶åé‡æ–°åŠ è½½
        if token_count > self.config.max_tokens {
            info!(
                "è¶…è¿‡tokenä¸Šé™ï¼Œè§¦å‘æ»šåŠ¨æ‘˜è¦: {}>{}",
                token_count, self.config.max_tokens
            );
            raw_msgs = self
                .rollup_and_persist_summary(repos, conv_id, &raw_msgs)
                .await?;
            token_count = self.estimate_tokens(&raw_msgs);
        }

        // 2. æ™ºèƒ½å‹ç¼©åˆ¤æ–­é€»è¾‘
        let compression_decision = self.make_compression_decision(&raw_msgs, token_count);

        let processed_msgs = match compression_decision {
            CompressionDecision::NoCompression => {
                debug!("æ— éœ€å‹ç¼©ï¼Œæ‰§è¡Œå¾ªç¯æ£€æµ‹");
                self.loop_detector.remove_loops(raw_msgs)
            }
            CompressionDecision::LightCompression => {
                debug!("æ‰§è¡Œè½»é‡å‹ç¼©");
                self.apply_light_compression(&raw_msgs)?
            }
            CompressionDecision::HeavyCompression => {
                info!(
                    "æ‰§è¡Œæ·±åº¦å‹ç¼©: tokens={}/{}, æ¶ˆæ¯æ•°={}",
                    token_count, self.config.max_tokens, original_count
                );
                let compressed = self.strategy.compress(&raw_msgs, &self.config)?;
                self.loop_detector.remove_loops(compressed)
            }
        };

        let final_token_count = self.estimate_tokens(&processed_msgs);

        debug!(
            "ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ: {} -> {} æ¡æ¶ˆæ¯, tokens: {} -> {}",
            original_count,
            processed_msgs.len(),
            token_count,
            final_token_count
        );

        Ok(ContextResult {
            messages: processed_msgs,
            original_count,
            token_count: final_token_count,
            compressed: !matches!(compression_decision, CompressionDecision::NoCompression),
        })
    }

    /// æ™ºèƒ½å‹ç¼©å†³ç­–
    fn make_compression_decision(
        &self,
        msgs: &[Message],
        token_count: usize,
    ) -> CompressionDecision {
        let token_ratio = token_count as f32 / self.config.max_tokens as f32;
        let msg_count = msgs.len();

        // è®¡ç®—å‹åŠ›æŒ‡æ ‡
        let token_pressure = token_ratio > self.config.compress_threshold;
        let message_pressure = msg_count > self.config.keep_recent + self.config.keep_important;
        let tool_message_ratio =
            msgs.iter().filter(|m| m.steps_json.is_some()).count() as f32 / msg_count as f32;

        match (token_pressure, message_pressure, tool_message_ratio > 0.6) {
            (false, false, _) => CompressionDecision::NoCompression,
            (false, true, false) => CompressionDecision::LightCompression,
            (true, _, _) | (_, true, true) => CompressionDecision::HeavyCompression,
        }
    }

    /// è½»é‡å‹ç¼© - ä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼Œç§»é™¤å†—ä½™
    fn apply_light_compression(&self, msgs: &[Message]) -> AppResult<Vec<Message>> {
        let mut result = Vec::new();
        let _scorer = AdvancedMessageScorer::new();

        // 1. ä¿ç•™æ‰€æœ‰ç³»ç»Ÿæ¶ˆæ¯
        result.extend(msgs.iter().filter(|m| m.role == "system").cloned());

        // 2. ä¿ç•™æ‰€æœ‰å·¥å…·æ‰§è¡Œæ¶ˆæ¯ï¼ˆå·¥å…·é“¾å®Œæ•´æ€§é‡è¦ï¼‰
        result.extend(msgs.iter().filter(|m| m.steps_json.is_some()).cloned());

        // 3. ä¿ç•™æœ€è¿‘çš„å¯¹è¯
        let recent_start = msgs.len().saturating_sub(self.config.keep_recent);
        for msg in &msgs[recent_start..] {
            if !result.iter().any(|m| m.id == msg.id) {
                result.push(msg.clone());
            }
        }

        // 4. ç§»é™¤ä½è´¨é‡é‡å¤æ¶ˆæ¯
        result.sort_by(|a, b| a.created_at.cmp(&b.created_at));
        result.dedup_by(|a, b| {
            if a.id == b.id {
                return true;
            }
            // å†…å®¹ç›¸ä¼¼åº¦å»é‡
            let similarity = self.content_similarity(&a.content, &b.content);
            similarity > 0.9 && (a.content.len() < b.content.len())
        });

        debug!("è½»é‡å‹ç¼©: {} -> {} æ¡æ¶ˆæ¯", msgs.len(), result.len());
        Ok(result)
    }

    /// è®¡ç®—å†…å®¹ç›¸ä¼¼åº¦
    fn content_similarity(&self, content1: &str, content2: &str) -> f64 {
        let words1: std::collections::HashSet<_> = content1.split_whitespace().collect();
        let words2: std::collections::HashSet<_> = content2.split_whitespace().collect();

        let intersection = words1.intersection(&words2).count();
        let union = words1.union(&words2).count();

        if union == 0 {
            0.0
        } else {
            intersection as f64 / union as f64
        }
    }

    /// æ„å»ºå¸¦æ‘˜è¦çš„prompt - é›†æˆKV Cache
    pub async fn build_prompt(
        &self,
        repos: &RepositoryManager,
        conv_id: i64,
        current_msg: &str,
        up_to_msg_id: Option<i64>,
    ) -> AppResult<String> {
        // 1. è·å–å†å²æ¶ˆæ¯ç”¨äºç¼“å­˜é”®è®¡ç®—ï¼ˆæ’é™¤å½“å‰æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯ï¼‰
        let raw_msgs = self.fetch_messages(repos, conv_id, up_to_msg_id).await?;

        // æ’é™¤æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆå½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼‰ï¼Œåªå¯¹å†å²æ¶ˆæ¯åšç¼“å­˜
        let history_msgs = if raw_msgs.len() > 1 {
            &raw_msgs[..raw_msgs.len() - 1]
        } else {
            &raw_msgs[..]
        };

        // 2. å°è¯•ä»KVç¼“å­˜è·å–
        if let Some(cached_prompt) = self.kv_cache.get(conv_id, history_msgs) {
            info!("KVç¼“å­˜å‘½ä¸­: conv={}", conv_id);

            // ç¼“å­˜å‘½ä¸­æ—¶ï¼Œåªéœ€è¦æ·»åŠ å½“å‰æ¶ˆæ¯
            return Ok(format!(
                "{}\n\nã€å½“å‰é—®é¢˜ã€‘\n{}",
                cached_prompt, current_msg
            ));
        }

        // 3. ç¼“å­˜æœªå‘½ä¸­ï¼Œæ„å»ºå®Œæ•´prompt
        info!("KVç¼“å­˜æœªå‘½ä¸­ï¼Œæ„å»ºæ–°prompt: conv={}", conv_id);

        let ctx = self.build_context(repos, conv_id, up_to_msg_id).await?;

        // è·å–ç”¨æˆ·å‰ç½®æç¤ºè¯
        let prefix = repos
            .ai_models()
            .get_user_prefix_prompt()
            .await?
            .unwrap_or_default();

        let mut parts = Vec::new();

        // æ·»åŠ å‰ç½®æç¤ºè¯ (ç¨³å®šå‰ç¼€)
        if !prefix.trim().is_empty() {
            parts.push(format!("ã€å‰ç½®æç¤ºã€‘\n{}\n", prefix));
        }

        // æ„å»ºå†å²å¯¹è¯ (å¯å˜éƒ¨åˆ†)
        if !ctx.messages.is_empty() {
            let history = ctx
                .messages
                .iter()
                .map(|m| self.format_message(m))
                .collect::<Vec<_>>()
                .join("\n");

            let compression_info = if ctx.compressed {
                format!("ï¼Œå·²æ™ºèƒ½å‹ç¼©è‡³{}æ¡", ctx.messages.len())
            } else {
                String::new()
            };

            parts.push(format!(
                "ã€å¯¹è¯å†å²ã€‘(å…±{}æ¡æ¶ˆæ¯{})\n{}\n",
                ctx.original_count, compression_info, history
            ));
        }

        // 4. ç¼“å­˜ç¨³å®šéƒ¨åˆ† (å‰ç¼€ + å†å²å¯¹è¯)
        let stable_content = parts.join("\n");
        self.kv_cache
            .put(conv_id, history_msgs, stable_content.clone());

        // 5. æ·»åŠ å½“å‰é—®é¢˜å¹¶è¿”å›
        parts.push(format!("ã€å½“å‰é—®é¢˜ã€‘\n{}", current_msg));
        Ok(parts.join("\n"))
    }

    // ============= ç§æœ‰æ–¹æ³• =============

    async fn fetch_messages(
        &self,
        repos: &RepositoryManager,
        conv_id: i64,
        _up_to_msg_id: Option<i64>,
    ) -> AppResult<Vec<Message>> {
        // TODO: å®ç°up_to_message_idé€»è¾‘
        let all = repos
            .conversations()
            .get_messages(conv_id, None, None)
            .await?;

        // æŸ¥æ‰¾æœ€æ–°æ‘˜è¦æ¶ˆæ¯ï¼ˆstatus ä»¥ "summary" å¼€å¤´çš„ system æ¶ˆæ¯ï¼‰
        let latest_summary_idx = all
            .iter()
            .enumerate()
            .rev()
            .find(|(_, m)| m.role == "system" && m.status.as_deref().map(|s| s.starts_with("summary")).unwrap_or(false))
            .map(|(i, _)| i);

        if let Some(idx) = latest_summary_idx {
            // ä»…ä¿ç•™è¯¥æ‘˜è¦ä»¥åŠå…¶åçš„æ¶ˆæ¯
            let mut compacted = Vec::new();
            compacted.push(all[idx].clone());
            compacted.extend(all.into_iter().skip(idx + 1));
            Ok(compacted)
        } else {
            Ok(all)
        }
    }

    /// æ™ºèƒ½tokenä¼°ç®— - è€ƒè™‘ä¸åŒå†…å®¹ç±»å‹
    fn estimate_tokens(&self, msgs: &[Message]) -> usize {
        msgs.iter()
            .map(|msg| self.estimate_single_message_tokens(msg))
            .sum()
    }

    /// ä¼°ç®—å•æ¡æ¶ˆæ¯çš„tokenæ•°
    fn estimate_single_message_tokens(&self, msg: &Message) -> usize {
        // ä½¿ç”¨çœŸå®åˆ†è¯å™¨è¿›è¡Œç²¾ç¡®ç»Ÿè®¡
        let mut tokens = self.tokenizer.encode_ordinary(&msg.content).len();
        if let Some(ref steps_json) = msg.steps_json {
            tokens += self.tokenizer.encode_ordinary(steps_json).len();
        }
        tokens += match msg.role.as_str() {
            "system" => 6,
            "assistant" => 4,
            "user" => 3,
            _ => 2,
        };
        tokens
    }

    /// ç”Ÿæˆæ»šåŠ¨æ‘˜è¦å¹¶æŒä¹…åŒ–ï¼Œè¿”å›ç´§å‡‘åçš„æ¶ˆæ¯åºåˆ—
    async fn rollup_and_persist_summary(
        &self,
        repos: &RepositoryManager,
        conv_id: i64,
        msgs: &[Message],
    ) -> AppResult<Vec<Message>> {
        // ç­–ç•¥ï¼šä¿ç•™æœ€è¿‘ keep_recent æ¡å’Œæ‰€æœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œå¯¹æ›´æ—©çš„ç”¨æˆ·/åŠ©æ‰‹å¯¹è¯åšæ‘˜è¦
        let keep_recent = self.config.keep_recent;

        let recent_start = msgs.len().saturating_sub(keep_recent);
        let (head, tail) = msgs.split_at(recent_start);

        // ä½¿ç”¨é›†åˆé«˜æ•ˆå»é‡ï¼šç³»ç»Ÿæ¶ˆæ¯ + æœ€è¿‘æ¶ˆæ¯
        let mut preserved_ids: HashSet<Option<i64>> = HashSet::new();
        for m in msgs.iter().filter(|m| m.role == "system") {
            preserved_ids.insert(m.id);
        }
        for m in tail.iter() {
            preserved_ids.insert(m.id);
        }

        // éœ€è¦è¢«æ‘˜è¦çš„åŒºé—´ï¼šheadï¼ˆæ—©æœŸéƒ¨åˆ†ï¼‰ä¸­éç³»ç»Ÿä¸”ä¸åœ¨ä¿ç•™é›†åˆçš„æ¶ˆæ¯
        let to_summarize: Vec<Message> = head
            .iter()
            .filter(|m| m.role != "system" && !preserved_ids.contains(&m.id))
            .cloned()
            .collect();

        if to_summarize.is_empty() {
            // æ²¡æœ‰éœ€è¦æ‘˜è¦çš„å†…å®¹ï¼Œç›´æ¥è¿”å›åŸå§‹
            return Ok(msgs.to_vec());
        }

        let summary_text = self.generate_rolling_summary(&to_summarize);

        // è®¡ç®—ç‰ˆæœ¬å·
        let latest_version = msgs
            .iter()
            .filter_map(|m| m.status.as_deref())
            .filter(|s| s.starts_with("summary_v"))
            .filter_map(|s| s.trim_start_matches("summary_v").parse::<u32>().ok())
            .max()
            .unwrap_or(0);
        let next_version = latest_version + 1;

        // æŒä¹…åŒ–æ‘˜è¦ä¸ºsystemæ¶ˆæ¯
        let mut summary_msg = crate::storage::repositories::conversations::Message::new(
            conv_id,
            "system".to_string(),
            summary_text,
        );
        summary_msg.status = Some(format!("summary_v{}", next_version));
        repos.conversations().save_message(&summary_msg).await?;

        // é‡æ–°è·å–å¹¶å‹ç¼©ï¼ˆfetch_messagesä¼šæ ¹æ®æœ€æ–°æ‘˜è¦è¿›è¡ŒæŠ˜å ï¼‰
        let compacted = self.fetch_messages(repos, conv_id, None).await?;
        Ok(compacted)
    }

    /// ç®€æ´çš„æ»šåŠ¨æ‘˜è¦ç”Ÿæˆ
    fn generate_rolling_summary(&self, msgs: &[Message]) -> String {
        // æå–å…³é”®ä¿¡æ¯ï¼š
        // - ç”¨æˆ·æé—®è¦ç‚¹
        // - åŠ©æ‰‹ç»“è®º/ç­”æ¡ˆ
        // - å·¥å…·æ‰§è¡Œæ‘˜è¦
        // æ§åˆ¶é•¿åº¦ï¼š~400-600 tokens ä»¥å†…ï¼ˆä¾é åˆ†è¯å™¨çº¦æŸï¼‰
        let mut bullets: Vec<String> = Vec::new();

        for m in msgs {
            match m.role.as_str() {
                "user" => {
                    bullets.push(format!("[User] {}", truncate_for_summary(&m.content)));
                }
                "assistant" => {
                    if let Some(steps) = &m.steps_json {
                        // ç²—ç•¥æå–å·¥å…·æ‘˜è¦
                        bullets.push(format!(
                            "[Tool] {}",
                            truncate_for_summary(steps)
                        ));
                    }
                    bullets.push(format!(
                        "[Assistant] {}",
                        truncate_for_summary(&m.content)
                    ));
                }
                _ => {}
            }
        }

        // åˆæˆæ‘˜è¦æ–‡æœ¬ï¼Œé™åˆ¶æœ€å¤§tokenæ•°ï¼ˆç²—ç•¥æ§åˆ¶ï¼‰
        let mut summary = String::from("Rolling Summary:\n");
        for b in bullets {
            summary.push_str("- ");
            summary.push_str(&b);
            summary.push('\n');
            // ç®€å•é˜²çˆ†ï¼šè¶…è¿‡ä¸€å®šé•¿åº¦å°±åœæ­¢
            if self.tokenizer.encode_ordinary(&summary).len() > 1200 {
                summary.push_str("... (truncated)\n");
                break;
            }
        }
        summary
    }


    fn format_message(&self, msg: &Message) -> String {
        if msg.role == "assistant" && msg.steps_json.is_some() {
            let steps_json = msg.steps_json.as_ref().unwrap();
            info!("ğŸ” åŸå§‹steps_json: {}", steps_json);

            if let Ok(steps_value) = serde_json::from_str(steps_json) {
                let tool_summary = self.extract_tool_summary(&steps_value);

                // AbortErrorç‰¹æ®Šå¤„ç†: åªä¿ç•™å·¥å…·ä¿¡æ¯ï¼Œä¸æ˜¾ç¤ºä¸­æ–­æ–‡æœ¬
                if msg.content.contains("AbortError") {
                    return format!("assistant: {}", tool_summary);
                }

                // æ­£å¸¸å·¥å…·æ¶ˆæ¯: ç»“åˆå·¥å…·æ‘˜è¦å’Œæœ€ç»ˆå†…å®¹
                return format!("assistant: {}\n{}", tool_summary, msg.content.trim());
            }
        }

        // é»˜è®¤æ ¼å¼åŒ–
        format!("{}: {}", msg.role, msg.content)
    }

    fn extract_tool_summary(&self, steps: &serde_json::Value) -> String {
        if let Some(array) = steps.as_array() {
            let mut segments: Vec<String> = Vec::new();

            for step in array {
                if step.get("type").and_then(|t| t.as_str()) == Some("tool_use") {
                    if let Some(tool_exec) = step.get("toolExecution") {
                        let tool_name = tool_exec
                            .get("name")
                            .and_then(|n| n.as_str())
                            .unwrap_or("unknown");
                        let status = tool_exec
                            .get("status")
                            .and_then(|s| s.as_str())
                            .unwrap_or("completed");

                        // æå–å·¥å…·è¾“å‡ºæ–‡æœ¬
                        let mut output_text = String::new();
                        if let Some(result) = tool_exec.get("result") {
                            // 1) å­—ç¬¦ä¸²ç»“æœ
                            if let Some(s) = result.as_str() {
                                output_text = s.to_string();
                            // 2) ç®€å•å¯¹è±¡å«textå­—æ®µ
                            } else if let Some(text) = result.get("text").and_then(|t| t.as_str()) {
                                output_text = text.to_string();
                            // 3) æ ‡å‡†å¯¹è±¡æ•°ç»„å†…å®¹
                            } else if let Some(contents) = result.get("content").and_then(|c| c.as_array()) {
                                let mut pieces: Vec<String> = Vec::new();
                                for item in contents {
                                    if let Some(t) = item.get("text").and_then(|t| t.as_str()) {
                                        pieces.push(t.to_string());
                                    } else if let Some(p) = item.get("path").and_then(|p| p.as_str()) {
                                        pieces.push(format!("[file] {}", p));
                                    } else if let Some(url) = item.get("url").and_then(|u| u.as_str()) {
                                        pieces.push(format!("[url] {}", url));
                                    }
                                }
                                output_text = pieces.join("\n");
                            }
                        }

                        // é”™è¯¯æ£€æµ‹ï¼šæ–‡æœ¬ä¸­åŒ…å«ToolErroræˆ–çŠ¶æ€ä¸ºfailed/error
                        let is_error = output_text.contains("ToolError:")
                            || tool_exec
                                .get("status")
                                .and_then(|s| s.as_str())
                                .map(|s| s.eq_ignore_ascii_case("failed") || s.eq_ignore_ascii_case("error"))
                                .unwrap_or(false);

                        let header = if is_error {
                            format!("{}(failed)", tool_name)
                        } else {
                            format!("{}({})", tool_name, status)
                        };

                        // å®‰å…¨æˆªæ–­ï¼šé™åˆ¶å­—ç¬¦æ•°ä¸è¡Œæ•°
                        if !output_text.trim().is_empty() {
                            let max_chars: usize = 800;
                            let max_lines: usize = 20;

                            // å…ˆæŒ‰å­—ç¬¦æˆªæ–­
                            let mut truncated = if output_text.chars().count() > max_chars {
                                let mut s: String = output_text.chars().take(max_chars).collect();
                                s.push_str("\nâ€¦(truncated)");
                                s
                            } else {
                                output_text
                            };

                            // å†æŒ‰è¡Œæˆªæ–­
                            let mut lines: Vec<&str> = truncated.lines().collect();
                            if lines.len() > max_lines {
                                lines.truncate(max_lines);
                                truncated = format!("{}\nâ€¦(truncated)", lines.join("\n"));
                            }

                            segments.push(format!("{}:\n{}", header, truncated));
                        } else {
                            segments.push(header);
                        }
                    }
                }
            }

            if !segments.is_empty() {
                return format!("Tools: {}", segments.join("\n\n"));
            }
        }

        "Completed".to_string()
    }

    /// è·å–KVç¼“å­˜ç»Ÿè®¡
    pub fn cache_stats(&self) -> CacheStats {
        self.kv_cache.stats()
    }

    /// æ¸…ç†è¿‡æœŸç¼“å­˜
    pub fn cleanup_cache(&self) {
        self.kv_cache.cleanup_expired()
    }

    /// æ‰‹åŠ¨å¤±æ•ˆç¼“å­˜ (å½“å¯¹è¯è¢«ä¿®æ”¹æ—¶è°ƒç”¨)
    pub fn invalidate_cache(&self, conv_id: i64) {
        let mut cache = self.kv_cache.cache.lock().unwrap();
        cache.retain(|key, _| !key.contains(&format!("ctx_{}_", conv_id)));
        info!("æ‰‹åŠ¨å¤±æ•ˆç¼“å­˜: conv={}", conv_id);
    }
}

/// å°†é•¿æ–‡æœ¬å®‰å…¨æˆªæ–­ç”¨äºæ‘˜è¦ï¼š
/// - å»é™¤å›´æ ä»£ç æ ‡è®°
/// - é™åˆ¶æœ€å¤§è¡Œæ•°ä¸å­—ç¬¦æ•°
/// - åœ¨è¢«æˆªæ–­æ—¶è¿½åŠ çœç•¥æ ‡è®°
fn truncate_for_summary<T: AsRef<str>>(text: T) -> String {
    let mut s = text.as_ref().trim().to_string();
    if s.is_empty() {
        return s;
    }

    // å»é™¤```å›´æ ï¼Œå‡å°‘æ— æ•ˆtoken
    if s.contains("```") {
        s = s.replace("```", "");
    }

    // æŒ‰è¡Œæˆªæ–­ï¼ˆä¼˜å…ˆä¿ç•™å‰å‡ è¡Œè¦ç‚¹ï¼‰
    let max_lines: usize = 8;
    let mut lines: Vec<&str> = s.lines().map(|l| l.trim_end()).collect();
    if lines.len() > max_lines {
        lines.truncate(max_lines);
    }
    let mut out = lines.join("\n");

    // æŒ‰å­—ç¬¦æˆªæ–­ï¼ˆæ§åˆ¶ç‰‡æ®µé•¿åº¦ï¼‰
    let max_chars: usize = 320;
    if out.chars().count() > max_chars {
        out = out.chars().take(max_chars).collect();
        out.push_str("\nâ€¦(truncated)");
    }
    out
}

// ============= ç»“æœç±»å‹ =============

/// ä¸Šä¸‹æ–‡æ„å»ºç»“æœ
#[derive(Debug)]
pub struct ContextResult {
    pub messages: Vec<Message>,
    pub original_count: usize,
    pub token_count: usize,
    pub compressed: bool,
}

impl ContextResult {
    /// è½¬ä¸ºAIä¸Šä¸‹æ–‡æ ¼å¼
    pub fn to_ai_context(self) -> crate::ai::types::AIContext {
        crate::ai::types::AIContext {
            chat_history: Some(self.messages),
            ..Default::default()
        }
    }
}

// ============= å·¥å‚æ–¹æ³• =============

/// åˆ›å»ºé»˜è®¤ä¸Šä¸‹æ–‡ç®¡ç†å™¨
pub fn create_context_manager() -> ContextManager {
    ContextManager::new(ContextConfig::default())
}

/// åˆ›å»ºè‡ªå®šä¹‰é…ç½®çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
pub fn create_context_manager_with_config(config: ContextConfig) -> ContextManager {
    ContextManager::new(config)
}
