/*!
 * ç½‘ç»œè¯·æ±‚å‘½ä»¤æ¨¡å—
 *
 * æä¾›æ— å¤´ HTTP è¯·æ±‚åŠŸèƒ½ï¼Œç»•è¿‡æµè§ˆå™¨çš„ CORS é™åˆ¶
 */

use anyhow::Result;
use html2text::from_read;
use scraper::{Html, Selector};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::time::Duration;
use tauri::command;

#[derive(Debug, Serialize, Deserialize)]
pub struct WebFetchRequest {
    pub url: String,
    pub method: Option<String>,
    pub headers: Option<HashMap<String, String>>,
    pub body: Option<String>,
    pub timeout: Option<u64>,
    pub follow_redirects: Option<bool>,
    pub response_format: Option<String>,
    pub extract_content: Option<bool>,
    pub max_content_length: Option<usize>,
    // æ™ºèƒ½å†…å®¹æå–å‚æ•°
    pub use_jina_reader: Option<bool>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct WebFetchResponse {
    pub status: u16,
    pub status_text: String,
    pub headers: HashMap<String, String>,
    pub data: String,
    pub response_time: u64,
    pub final_url: String,
    pub success: bool,
    pub error: Option<String>,
    pub content_type: Option<String>,
    pub content_length: Option<usize>,
    pub extracted_text: Option<String>,
    pub page_title: Option<String>,
}

/// æ‰§è¡Œæ— å¤´ HTTP è¯·æ±‚
#[command]
pub async fn network_web_fetch_headless(request: WebFetchRequest) -> Result<WebFetchResponse, String> {
    tracing::debug!("ğŸŒ [WebFetch] å¼€å§‹æ— å¤´è¯·æ±‚: {}", request.url);

    let start_time = std::time::Instant::now();

    // éªŒè¯ URL
    let url = match reqwest::Url::parse(&request.url) {
        Ok(url) => url,
        Err(e) => {
            let error_msg = format!("æ— æ•ˆçš„ URL: {}", e);
            tracing::error!("âŒ [WebFetch] {}", error_msg);
            return Ok(WebFetchResponse {
                status: 0,
                status_text: "Invalid URL".to_string(),
                headers: HashMap::new(),
                data: String::new(),
                response_time: start_time.elapsed().as_millis() as u64,
                final_url: request.url,
                success: false,
                error: Some(error_msg),
                content_type: None,
                content_length: None,
                extracted_text: None,
                page_title: None,
            });
        }
    };

    // æ„å»º HTTP å®¢æˆ·ç«¯
    #[cfg(debug_assertions)]
    let client_builder = reqwest::Client::builder()
        .timeout(Duration::from_millis(request.timeout.unwrap_or(10000)))
        .redirect(if request.follow_redirects.unwrap_or(true) {
            reqwest::redirect::Policy::limited(10)
        } else {
            reqwest::redirect::Policy::none()
        })
        .user_agent("Eko-Agent/1.0")
        .danger_accept_invalid_certs(true);

    #[cfg(not(debug_assertions))]
    let client_builder = reqwest::Client::builder()
        .timeout(Duration::from_millis(request.timeout.unwrap_or(10000)))
        .redirect(if request.follow_redirects.unwrap_or(true) {
            reqwest::redirect::Policy::limited(10)
        } else {
            reqwest::redirect::Policy::none()
        })
        .user_agent("Eko-Agent/1.0");

    let client = match client_builder.build() {
        Ok(client) => client,
        Err(e) => {
            let error_msg = format!("åˆ›å»º HTTP å®¢æˆ·ç«¯å¤±è´¥: {}", e);
            tracing::error!("âŒ [WebFetch] {}", error_msg);
            return Ok(WebFetchResponse {
                status: 0,
                status_text: "Client Error".to_string(),
                headers: HashMap::new(),
                data: String::new(),
                response_time: start_time.elapsed().as_millis() as u64,
                final_url: request.url,
                success: false,
                error: Some(error_msg),
                content_type: None,
                content_length: None,
                extracted_text: None,
                page_title: None,
            });
        }
    };

    // æ„å»ºè¯·æ±‚
    let method = match request
        .method
        .as_deref()
        .unwrap_or("GET")
        .to_uppercase()
        .as_str()
    {
        "GET" => reqwest::Method::GET,
        "POST" => reqwest::Method::POST,
        "PUT" => reqwest::Method::PUT,
        "DELETE" => reqwest::Method::DELETE,
        "PATCH" => reqwest::Method::PATCH,
        "HEAD" => reqwest::Method::HEAD,
        "OPTIONS" => reqwest::Method::OPTIONS,
        _ => reqwest::Method::GET,
    };

    let mut request_builder = client.request(method, url);

    // æ·»åŠ è¯·æ±‚å¤´
    if let Some(headers) = &request.headers {
        for (key, value) in headers {
            request_builder = request_builder.header(key, value);
        }
    }

    // æ·»åŠ è¯·æ±‚ä½“
    if let Some(body) = &request.body {
        request_builder = request_builder.body(body.clone());
    }

    tracing::info!("ğŸš€ [WebFetch] å‘é€è¯·æ±‚åˆ°: {}", request.url);

    // å‘é€è¯·æ±‚
    match request_builder.send().await {
        Ok(response) => {
            let status = response.status().as_u16();
            let status_text = response
                .status()
                .canonical_reason()
                .unwrap_or("Unknown")
                .to_string();
            let final_url = response.url().to_string();

            let mut headers = HashMap::new();
            for (key, value) in response.headers() {
                if let Ok(value_str) = value.to_str() {
                    headers.insert(key.to_string(), value_str.to_string());
                }
            }

            tracing::debug!("ğŸ“¡ [WebFetch] æ”¶åˆ°å“åº”: {} {}", status, status_text);

            let content_type = headers.get("content-type").cloned();

            let raw_data = match response.text().await {
                Ok(text) => text,
                Err(e) => {
                    return Ok(WebFetchResponse {
                        status: 0,
                        status_text: "Read Error".to_string(),
                        headers: HashMap::new(),
                        data: format!("è¯»å–å“åº”å¤±è´¥: {}", e),
                        response_time: start_time.elapsed().as_millis() as u64,
                        final_url,
                        success: false,
                        error: Some(format!("è¯»å–å“åº”å¤±è´¥: {}", e)),
                        content_type: None,
                        content_length: None,
                        extracted_text: None,
                        page_title: None,
                    })
                }
            };

            let content_length = Some(raw_data.len());
            let extract_content = request.extract_content.unwrap_or(true);
            let max_length = request.max_content_length.unwrap_or(2000);

            // å†…å®¹æå–ï¼ˆä»…å¯¹ HTML å†…å®¹ï¼‰
            let (extracted_text, page_title) = if extract_content
                && content_type
                    .as_ref()
                    .is_some_and(|ct| ct.contains("text/html"))
            {
                // ä½¿ç”¨æ”¹è¿›çš„å†…å®¹æå–ç®—æ³•
                let (text, title) = extract_content_from_html_improved(&raw_data, max_length);
                (Some(text), title)
            } else {
                (None, None)
            };

            let final_data = if extract_content && extracted_text.is_some() {
                create_content_summary(extracted_text.as_ref().unwrap(), &final_url)
            } else {
                match request.response_format.as_deref().unwrap_or("text") {
                    "json" => {
                        match serde_json::from_str::<serde_json::Value>(&raw_data) {
                            Ok(json) => serde_json::to_string_pretty(&json).unwrap_or(raw_data),
                            Err(_) => raw_data, // å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œè¿”å›åŸå§‹æ–‡æœ¬
                        }
                    }
                    _ => {
                        // é™åˆ¶åŸå§‹æ•°æ®é•¿åº¦
                        if raw_data.len() > max_length {
                            format!(
                                "{}...\n\n[å†…å®¹è¢«æˆªæ–­ï¼Œæ€»é•¿åº¦: {} å­—ç¬¦]",
                                &raw_data[..max_length],
                                raw_data.len()
                            )
                        } else {
                            raw_data
                        }
                    }
                }
            };

            let response_time = start_time.elapsed().as_millis() as u64;

            Ok(WebFetchResponse {
                status,
                status_text,
                headers,
                data: final_data,
                response_time,
                final_url,
                success: (200..400).contains(&status),
                error: None,
                content_type,
                content_length,
                extracted_text,
                page_title,
            })
        }
        Err(e) => {
            let error_msg = format!("è¯·æ±‚å¤±è´¥: {}", e);
            tracing::error!("âŒ [WebFetch] {}", error_msg);

            Ok(WebFetchResponse {
                status: 0,
                status_text: "Request Failed".to_string(),
                headers: HashMap::new(),
                data: String::new(),
                response_time: start_time.elapsed().as_millis() as u64,
                final_url: request.url,
                success: false,
                error: Some(error_msg),
                content_type: None,
                content_length: None,
                extracted_text: None,
                page_title: None,
            })
        }
    }
}

/// ç®€åŒ–çš„ç½‘ç»œè¯·æ±‚å‘½ä»¤ï¼ˆåªéœ€è¦ URLï¼‰
#[command]
pub async fn network_simple_web_fetch(url: String) -> Result<WebFetchResponse, String> {
    let request = WebFetchRequest {
        url,
        method: Some("GET".to_string()),
        headers: None,
        body: None,
        timeout: Some(15000), // 15ç§’è¶…æ—¶
        follow_redirects: Some(true),
        response_format: Some("text".to_string()),
        extract_content: Some(true),
        max_content_length: Some(2000),
        use_jina_reader: Some(false), // ä¸ä½¿ç”¨jina_reader
    };

    network_web_fetch_headless(request).await
}

/// æå– HTML å†…å®¹çš„ä¸»è¦æ–‡æœ¬ï¼ˆæ”¹è¿›ç‰ˆï¼‰
fn extract_content_from_html_improved(html: &str, max_length: usize) -> (String, Option<String>) {
    let document = Html::parse_document(html);

    // æå–é¡µé¢æ ‡é¢˜
    let title = if let Ok(title_selector) = Selector::parse("title") {
        document
            .select(&title_selector)
            .next()
            .map(|element| element.text().collect::<String>().trim().to_string())
    } else {
        None
    };

    // ä½¿ç”¨ scraper ç§»é™¤ä¸éœ€è¦çš„å…ƒç´ 
    let mut cleaned_html = html.to_string();

    // ç§»é™¤ä¸éœ€è¦çš„å…ƒç´ ï¼ˆæ”¹è¿›ç‰ˆï¼‰
    let unwanted_tags = [
        ("script", "</script>"),
        ("style", "</style>"),
        ("nav", "</nav>"),
        ("header", "</header>"),
        ("footer", "</footer>"),
        ("aside", "</aside>"),
        ("noscript", "</noscript>"),
    ];

    for (start_tag, end_tag) in &unwanted_tags {
        while let Some(start) = cleaned_html.find(&format!("<{}", start_tag)) {
            if let Some(end) = cleaned_html[start..].find(end_tag) {
                let end_pos = start + end + end_tag.len();
                cleaned_html.replace_range(start..end_pos, "");
            } else {
                break;
            }
        }
    }

    // è½¬æ¢ä¸ºçº¯æ–‡æœ¬
    let text = from_read(cleaned_html.as_bytes(), max_length);

    // æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
    let cleaned_text = text
        .lines()
        .map(|line| line.trim())
        .filter(|line| !line.is_empty())
        .collect::<Vec<_>>()
        .join("\n");

    // é™åˆ¶é•¿åº¦
    let final_text = if cleaned_text.len() > max_length {
        format!(
            "{}...\n\n[å†…å®¹è¢«æˆªæ–­ï¼ŒåŸå§‹é•¿åº¦: {} å­—ç¬¦]",
            &cleaned_text[..max_length],
            cleaned_text.len()
        )
    } else {
        cleaned_text
    };

    (final_text, title)
}

/// æ™ºèƒ½å†…å®¹æ‘˜è¦
fn create_content_summary(content: &str, _url: &str) -> String {
    let lines: Vec<&str> = content.lines().collect();
    let total_lines = lines.len();

    if total_lines <= 50 {
        return content.to_string();
    }

    // å–å‰20è¡Œå’Œå10è¡Œï¼Œä¸­é—´æ˜¾ç¤ºçœç•¥ä¿¡æ¯
    let mut summary = Vec::new();

    // å‰20è¡Œ
    for line in lines.iter().take(20) {
        summary.push(line.to_string());
    }

    // çœç•¥ä¿¡æ¯
    summary.push(format!("\n... [çœç•¥äº† {} è¡Œå†…å®¹] ...\n", total_lines - 30));

    // å10è¡Œ
    for line in lines.iter().skip(total_lines - 10) {
        summary.push(line.to_string());
    }

    summary.join("\n")
}
